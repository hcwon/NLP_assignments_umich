{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "58HHLU8iIIO0"
   },
   "outputs": [],
   "source": [
    "!pip install transformers[sentencepiece]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7iKrWjZJIz2y"
   },
   "outputs": [],
   "source": [
    "!pip install datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "yDHI9aVYJDC7"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from scipy.stats import pearsonr\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "from transformers import AdamW, AutoTokenizer, DataCollatorWithPadding, AutoModelForSequenceClassification, get_scheduler, TrainingArguments, Trainer\n",
    "from datasets import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "id": "BEw4Az-CJ6qY"
   },
   "outputs": [],
   "source": [
    "# Here the loaded data is processed in hw3_trainer_pre_process.ipynb\n",
    "data_train = pd.read_csv('data_train_reg.csv')\n",
    "data_dev = pd.read_csv('data_dev_reg.csv')\n",
    "data_test = pd.read_csv('data_test.csv')\n",
    "\n",
    "trainset = Dataset.from_pandas(data_train)\n",
    "devset = Dataset.from_pandas(data_dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "ig6ryqXVKSXQ",
    "outputId": "265f23e7-0c92-4f15-b457-b54dc53313f8"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-0fd3c800-35e7-4acb-a9b4-043e8f8d08b7\">\n",
       "    <div class=\"colab-df-container\">\n",
       "      <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question_text</th>\n",
       "      <th>reply_text</th>\n",
       "      <th>rate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Is there someone you turned down in the past, ...</td>\n",
       "      <td>Idk if this counts but my when I was younger m...</td>\n",
       "      <td>4.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>What is, in your opinion, the saddest villain ...</td>\n",
       "      <td>My man Dr Heinz Doofenschmirts was born withou...</td>\n",
       "      <td>3.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ELI5: How do we still not know how eels reprod...</td>\n",
       "      <td>For a long time, it wasn't known how eels mate...</td>\n",
       "      <td>3.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ELI5: Why can’t freshwater fish live in saltwa...</td>\n",
       "      <td>A living cell is designed to work at specific ...</td>\n",
       "      <td>4.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>What's something nice you like to do just to b...</td>\n",
       "      <td>Give compliments. It’s extremely easy to do an...</td>\n",
       "      <td>4.40</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-0fd3c800-35e7-4acb-a9b4-043e8f8d08b7')\"\n",
       "              title=\"Convert this dataframe to an interactive table.\"\n",
       "              style=\"display:none;\">\n",
       "        \n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
       "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
       "  </svg>\n",
       "      </button>\n",
       "      \n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      flex-wrap:wrap;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "      <script>\n",
       "        const buttonEl =\n",
       "          document.querySelector('#df-0fd3c800-35e7-4acb-a9b4-043e8f8d08b7 button.colab-df-convert');\n",
       "        buttonEl.style.display =\n",
       "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "        async function convertToInteractive(key) {\n",
       "          const element = document.querySelector('#df-0fd3c800-35e7-4acb-a9b4-043e8f8d08b7');\n",
       "          const dataTable =\n",
       "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                     [key], {});\n",
       "          if (!dataTable) return;\n",
       "\n",
       "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "            + ' to learn more about interactive tables.';\n",
       "          element.innerHTML = '';\n",
       "          dataTable['output_type'] = 'display_data';\n",
       "          await google.colab.output.renderOutput(dataTable, element);\n",
       "          const docLink = document.createElement('div');\n",
       "          docLink.innerHTML = docLinkHtml;\n",
       "          element.appendChild(docLink);\n",
       "        }\n",
       "      </script>\n",
       "    </div>\n",
       "  </div>\n",
       "  "
      ],
      "text/plain": [
       "                                       question_text  \\\n",
       "0  Is there someone you turned down in the past, ...   \n",
       "1  What is, in your opinion, the saddest villain ...   \n",
       "2  ELI5: How do we still not know how eels reprod...   \n",
       "3  ELI5: Why can’t freshwater fish live in saltwa...   \n",
       "4  What's something nice you like to do just to b...   \n",
       "\n",
       "                                          reply_text  rate  \n",
       "0  Idk if this counts but my when I was younger m...  4.75  \n",
       "1  My man Dr Heinz Doofenschmirts was born withou...  3.75  \n",
       "2  For a long time, it wasn't known how eels mate...  3.50  \n",
       "3  A living cell is designed to work at specific ...  4.00  \n",
       "4  Give compliments. It’s extremely easy to do an...  4.40  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem11 Using trainer to do regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "I9tN-4fnKT6J"
   },
   "outputs": [],
   "source": [
    "# checkpoint = 'bert-base-uncased'\n",
    "# checkpoint = 'distilbert-base-uncased'\n",
    "checkpoint = \"microsoft/MiniLM-L12-H384-uncased\"  # the model has no maximum length parameter to pad with\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(checkpoint, model_max_length=512)\n",
    "\n",
    "# def tokenize_function(example):\n",
    "#     return tokenizer(example[\"question_text\"], example[\"reply_text\"], truncation=True)\n",
    "\n",
    "def tokenize_function(example):\n",
    "    return tokenizer(example[\"question_text\"], example[\"reply_text\"], truncation=True)\n",
    "\n",
    "tokenized_trainset = trainset.map(tokenize_function, batched=True)\n",
    "tokenized_devset = devset.map(tokenize_function, batched=True)\n",
    "\n",
    "# remove the unexpected text, only keep the tokenized data and the labels\n",
    "tokenized_trainset = tokenized_trainset.remove_columns([\"question_text\", \"reply_text\"])\n",
    "tokenized_trainset = tokenized_trainset.rename_column(\"rate\", \"labels\")\n",
    "tokenized_devset = tokenized_devset.remove_columns([\"question_text\", \"reply_text\"])\n",
    "tokenized_devset = tokenized_devset.rename_column(\"rate\", \"labels\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CHstVP_TKvL2"
   },
   "outputs": [],
   "source": [
    "# when using regression, the num_label should be set to 1\n",
    "model = AutoModelForSequenceClassification.from_pretrained(checkpoint, num_labels=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ptlcULC_K6ow",
    "outputId": "9dc02bb0-0851-4c26-e789-66a20f98dcdd"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch: setting up devices\n"
     ]
    }
   ],
   "source": [
    "args = TrainingArguments(\n",
    "    evaluation_strategy = \"epoch\",\n",
    "    save_strategy = \"epoch\",\n",
    "    learning_rate=3e-6,\n",
    "    num_train_epochs=6,\n",
    "    report_to=\"none\",\n",
    "    weight_decay=0.01,\n",
    "    output_dir='train_with_reg',\n",
    "    logging_steps = 400\n",
    ")\n",
    "\n",
    "\n",
    "trainer = Trainer(\n",
    "    model,\n",
    "    args,\n",
    "    train_dataset=tokenized_trainset,\n",
    "    eval_dataset=tokenized_devset,\n",
    "    tokenizer=tokenizer,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "pHLFSDeRLfyj",
    "outputId": "3acb1dc2-75bc-478e-df72-ce6dffe3b3bb",
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:309: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  FutureWarning,\n",
      "***** Running training *****\n",
      "  Num examples = 3779\n",
      "  Num Epochs = 6\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 2838\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2838' max='2838' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2838/2838 07:40, Epoch 6/6]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.037900</td>\n",
       "      <td>0.521022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.035700</td>\n",
       "      <td>0.511633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.033900</td>\n",
       "      <td>0.499932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.030900</td>\n",
       "      <td>0.508891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.033900</td>\n",
       "      <td>0.515199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.029600</td>\n",
       "      <td>0.513663</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 811\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to train_with_reg/checkpoint-473\n",
      "Configuration saved in train_with_reg/checkpoint-473/config.json\n",
      "Model weights saved in train_with_reg/checkpoint-473/pytorch_model.bin\n",
      "tokenizer config file saved in train_with_reg/checkpoint-473/tokenizer_config.json\n",
      "Special tokens file saved in train_with_reg/checkpoint-473/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 811\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to train_with_reg/checkpoint-946\n",
      "Configuration saved in train_with_reg/checkpoint-946/config.json\n",
      "Model weights saved in train_with_reg/checkpoint-946/pytorch_model.bin\n",
      "tokenizer config file saved in train_with_reg/checkpoint-946/tokenizer_config.json\n",
      "Special tokens file saved in train_with_reg/checkpoint-946/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 811\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to train_with_reg/checkpoint-1419\n",
      "Configuration saved in train_with_reg/checkpoint-1419/config.json\n",
      "Model weights saved in train_with_reg/checkpoint-1419/pytorch_model.bin\n",
      "tokenizer config file saved in train_with_reg/checkpoint-1419/tokenizer_config.json\n",
      "Special tokens file saved in train_with_reg/checkpoint-1419/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 811\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to train_with_reg/checkpoint-1892\n",
      "Configuration saved in train_with_reg/checkpoint-1892/config.json\n",
      "Model weights saved in train_with_reg/checkpoint-1892/pytorch_model.bin\n",
      "tokenizer config file saved in train_with_reg/checkpoint-1892/tokenizer_config.json\n",
      "Special tokens file saved in train_with_reg/checkpoint-1892/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 811\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to train_with_reg/checkpoint-2365\n",
      "Configuration saved in train_with_reg/checkpoint-2365/config.json\n",
      "Model weights saved in train_with_reg/checkpoint-2365/pytorch_model.bin\n",
      "tokenizer config file saved in train_with_reg/checkpoint-2365/tokenizer_config.json\n",
      "Special tokens file saved in train_with_reg/checkpoint-2365/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 811\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to train_with_reg/checkpoint-2838\n",
      "Configuration saved in train_with_reg/checkpoint-2838/config.json\n",
      "Model weights saved in train_with_reg/checkpoint-2838/pytorch_model.bin\n",
      "tokenizer config file saved in train_with_reg/checkpoint-2838/tokenizer_config.json\n",
      "Special tokens file saved in train_with_reg/checkpoint-2838/special_tokens_map.json\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=2838, training_loss=0.033256495939836775, metrics={'train_runtime': 460.6785, 'train_samples_per_second': 49.219, 'train_steps_per_second': 6.16, 'total_flos': 919839936934338.0, 'train_loss': 0.033256495939836775, 'epoch': 6.0})"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 89
    },
    "id": "Nm6lRczULnSA",
    "outputId": "0a08cb9a-199b-44d0-f24b-f60c103d54e8"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Prediction *****\n",
      "  Num examples = 811\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='102' max='102' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [102/102 00:04]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "predictions = trainer.predict(tokenized_devset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yr1yQaXvOG4I",
    "outputId": "71adf891-6ddb-4b8c-dbac-d24156639837"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean square error:  0.71670306\n",
      "Correlation:  0.6067053696840444\n"
     ]
    }
   ],
   "source": [
    "# calculate the performance\n",
    "\n",
    "print(\"Mean square error: \", mean_squared_error(predictions.label_ids, predictions.predictions, squared=False))\n",
    "print(\"Correlation: \", pearsonr(predictions.label_ids, predictions.predictions.flatten())[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "18nX206MNo1G"
   },
   "outputs": [],
   "source": [
    "predictions.predictions.flatten()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 12 Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 121,
     "referenced_widgets": [
      "c9ff2787542f4d6c91699c0e1afcc897",
      "b05a28b4720345c3b7c0cad404134418",
      "51940ef27e364ae0a690426addf49cc6",
      "b4f0e06f9d554ad2aabb3f39f1b3c390",
      "88a870f65d8e4811adb92dc17397e45b",
      "277d4b2c1621478b9202f6cad2944e66",
      "f72be50f00c244f28b1f85a0e8b2d1d7",
      "c7d02bec4b9b4bea921232ba93247b50",
      "c57cc4641cfb4af28283f539f62ae57a",
      "744aa07bf14a4dfe986992147dd7dba9",
      "6849ae29b37442eeaa49e539cc5690ab"
     ]
    },
    "id": "apn4Kptmefux",
    "outputId": "3ef88cb5-afc5-480b-b30d-9290415986a6"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c9ff2787542f4d6c91699c0e1afcc897",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Prediction *****\n",
      "  Num examples = 810\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='510' max='102' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [102/102 14:12]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# use the public test set to make predictions\n",
    "test_out = data_test[['id']]\n",
    "test_input = data_test[[\"question_text\", \"reply_text\"]]\n",
    "# test_input['labels'] = 1\n",
    "\n",
    "test_dt = Dataset.from_pandas(test_input)\n",
    "test_tkn = test_dt.map(tokenize_function, batched=True).remove_columns([\"question_text\", \"reply_text\"])\n",
    "\n",
    "pred_test = trainer.predict(test_tkn)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lNik5la5N8gt",
    "outputId": "3210142e-397b-40de-ed9f-131a3bd7a36d"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "label = pred_test.predictions.flatten()\n",
    "test_out['predicted'] = label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "id": "AbtWVALqOka5"
   },
   "outputs": [],
   "source": [
    "test_out.to_csv('upload.csv', index=False, encoding='utf8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eQ1Qy1PD8WrT"
   },
   "source": [
    "## Problem 13 evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "id": "qPVeejB_8chF"
   },
   "outputs": [],
   "source": [
    "# get the group_lst\n",
    "group_lst = pd.read_csv('si630w22-hw3-train.csv')['group'].unique().tolist()\n",
    "group_lst.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "H2tZNcRr9eDU"
   },
   "outputs": [],
   "source": [
    "train_dict = {}\n",
    "dev_a_dict = {}\n",
    "dev_b_dict = {}\n",
    "dev_c_dict = {}\n",
    "\n",
    "\n",
    "for g in group_lst:\n",
    "    train_dt = Dataset.from_pandas(pd.read_csv('P13_evaluation/' + g + '_train' + '.csv'))\n",
    "    dev_a_dt = Dataset.from_pandas(pd.read_csv('P13_evaluation/' + g + '_dev_a' + '.csv'))\n",
    "    dev_b_dt = Dataset.from_pandas(pd.read_csv('P13_evaluation/' + g + '_dev_b' + '.csv'))\n",
    "    dev_c_dt = Dataset.from_pandas(pd.read_csv('P13_evaluation/' + g + '_dev_c' + '.csv'))\n",
    "\n",
    "    trainset_tkn = train_dt.map(tokenize_function, batched=True).remove_columns([\"question_text\", \"reply_text\"]).rename_column(\"rate\", \"labels\")\n",
    "    dev_aset_tkn = dev_a_dt.map(tokenize_function, batched=True).remove_columns([\"question_text\", \"reply_text\"]).rename_column(\"rate\", \"labels\")\n",
    "    dev_bset_tkn = dev_b_dt.map(tokenize_function, batched=True).remove_columns([\"question_text\", \"reply_text\"]).rename_column(\"rate\", \"labels\")\n",
    "    dev_cset_tkn = dev_c_dt.map(tokenize_function, batched=True).remove_columns([\"question_text\", \"reply_text\"]).rename_column(\"rate\", \"labels\")\n",
    "\n",
    "    train_dict[g] = trainset_tkn\n",
    "    dev_a_dict[g] = dev_aset_tkn\n",
    "    dev_b_dict[g] = dev_bset_tkn\n",
    "    dev_c_dict[g] = dev_cset_tkn\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "referenced_widgets": [
      "738120ddbf9d4d95abb50f725475be79",
      "5a82eb9826d7462d9f19a9cf4aafc708",
      "d3d6c2d41c344c2b9f529d74e11fccc3",
      "24731db8569c4271bb8005ad21510a20",
      "3df8faa69fdf4903a3a39fb11680f9c1",
      "2c72af6399954523b3e9441e420c7848",
      "c190e36ed94f473b8db940d6176bf624",
      "610a54182baf4fe886c55b27d4d59c03",
      "1beab673debf4b11af3cd537351e4200",
      "8de35ac403ad45369837f1680a83080a",
      "9c33f9c1e1774bb5a43e72ef32b7adff"
     ]
    },
    "id": "__8LiiqXBfWq",
    "outputId": "c7d0def4-7580-4ab0-9337-dc869fa72149",
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "738120ddbf9d4d95abb50f725475be79",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/24 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:309: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  FutureWarning,\n",
      "***** Running training *****\n",
      "  Num examples = 3768\n",
      "  Num Epochs = 6\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 2826\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2826' max='2826' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2826/2826 07:16, Epoch 6/6]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.310300</td>\n",
       "      <td>0.545107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.315400</td>\n",
       "      <td>0.620307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.299300</td>\n",
       "      <td>0.535589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.294000</td>\n",
       "      <td>0.549302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.301900</td>\n",
       "      <td>0.548310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.281100</td>\n",
       "      <td>0.551716</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 809\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to train_with_reg/checkpoint-471\n",
      "Configuration saved in train_with_reg/checkpoint-471/config.json\n",
      "Model weights saved in train_with_reg/checkpoint-471/pytorch_model.bin\n",
      "tokenizer config file saved in train_with_reg/checkpoint-471/tokenizer_config.json\n",
      "Special tokens file saved in train_with_reg/checkpoint-471/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 809\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to train_with_reg/checkpoint-942\n",
      "Configuration saved in train_with_reg/checkpoint-942/config.json\n",
      "Model weights saved in train_with_reg/checkpoint-942/pytorch_model.bin\n",
      "tokenizer config file saved in train_with_reg/checkpoint-942/tokenizer_config.json\n",
      "Special tokens file saved in train_with_reg/checkpoint-942/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 809\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to train_with_reg/checkpoint-1413\n",
      "Configuration saved in train_with_reg/checkpoint-1413/config.json\n",
      "Model weights saved in train_with_reg/checkpoint-1413/pytorch_model.bin\n",
      "tokenizer config file saved in train_with_reg/checkpoint-1413/tokenizer_config.json\n",
      "Special tokens file saved in train_with_reg/checkpoint-1413/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 809\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to train_with_reg/checkpoint-1884\n",
      "Configuration saved in train_with_reg/checkpoint-1884/config.json\n",
      "Model weights saved in train_with_reg/checkpoint-1884/pytorch_model.bin\n",
      "tokenizer config file saved in train_with_reg/checkpoint-1884/tokenizer_config.json\n",
      "Special tokens file saved in train_with_reg/checkpoint-1884/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 809\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to train_with_reg/checkpoint-2355\n",
      "Configuration saved in train_with_reg/checkpoint-2355/config.json\n",
      "Model weights saved in train_with_reg/checkpoint-2355/pytorch_model.bin\n",
      "tokenizer config file saved in train_with_reg/checkpoint-2355/tokenizer_config.json\n",
      "Special tokens file saved in train_with_reg/checkpoint-2355/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 809\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to train_with_reg/checkpoint-2826\n",
      "Configuration saved in train_with_reg/checkpoint-2826/config.json\n",
      "Model weights saved in train_with_reg/checkpoint-2826/pytorch_model.bin\n",
      "tokenizer config file saved in train_with_reg/checkpoint-2826/tokenizer_config.json\n",
      "Special tokens file saved in train_with_reg/checkpoint-2826/special_tokens_map.json\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Prediction *****\n",
      "  Num examples = 809\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='122' max='102' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [102/102 00:05]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Prediction *****\n",
      "  Num examples = 77\n",
      "  Batch size = 8\n",
      "***** Running Prediction *****\n",
      "  Num examples = 75\n",
      "  Batch size = 8\n",
      "/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:309: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  FutureWarning,\n",
      "***** Running training *****\n",
      "  Num examples = 3767\n",
      "  Num Epochs = 6\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 2826\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2826' max='2826' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2826/2826 07:15, Epoch 6/6]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.284200</td>\n",
       "      <td>0.492242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.282000</td>\n",
       "      <td>0.619784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.261800</td>\n",
       "      <td>0.575809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.253800</td>\n",
       "      <td>0.529945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.258400</td>\n",
       "      <td>0.564575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.247400</td>\n",
       "      <td>0.558884</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 806\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to train_with_reg/checkpoint-471\n",
      "Configuration saved in train_with_reg/checkpoint-471/config.json\n",
      "Model weights saved in train_with_reg/checkpoint-471/pytorch_model.bin\n",
      "tokenizer config file saved in train_with_reg/checkpoint-471/tokenizer_config.json\n",
      "Special tokens file saved in train_with_reg/checkpoint-471/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 806\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to train_with_reg/checkpoint-942\n",
      "Configuration saved in train_with_reg/checkpoint-942/config.json\n",
      "Model weights saved in train_with_reg/checkpoint-942/pytorch_model.bin\n",
      "tokenizer config file saved in train_with_reg/checkpoint-942/tokenizer_config.json\n",
      "Special tokens file saved in train_with_reg/checkpoint-942/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 806\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to train_with_reg/checkpoint-1413\n",
      "Configuration saved in train_with_reg/checkpoint-1413/config.json\n",
      "Model weights saved in train_with_reg/checkpoint-1413/pytorch_model.bin\n",
      "tokenizer config file saved in train_with_reg/checkpoint-1413/tokenizer_config.json\n",
      "Special tokens file saved in train_with_reg/checkpoint-1413/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 806\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to train_with_reg/checkpoint-1884\n",
      "Configuration saved in train_with_reg/checkpoint-1884/config.json\n",
      "Model weights saved in train_with_reg/checkpoint-1884/pytorch_model.bin\n",
      "tokenizer config file saved in train_with_reg/checkpoint-1884/tokenizer_config.json\n",
      "Special tokens file saved in train_with_reg/checkpoint-1884/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 806\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to train_with_reg/checkpoint-2355\n",
      "Configuration saved in train_with_reg/checkpoint-2355/config.json\n",
      "Model weights saved in train_with_reg/checkpoint-2355/pytorch_model.bin\n",
      "tokenizer config file saved in train_with_reg/checkpoint-2355/tokenizer_config.json\n",
      "Special tokens file saved in train_with_reg/checkpoint-2355/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 806\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to train_with_reg/checkpoint-2826\n",
      "Configuration saved in train_with_reg/checkpoint-2826/config.json\n",
      "Model weights saved in train_with_reg/checkpoint-2826/pytorch_model.bin\n",
      "tokenizer config file saved in train_with_reg/checkpoint-2826/tokenizer_config.json\n",
      "Special tokens file saved in train_with_reg/checkpoint-2826/special_tokens_map.json\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Prediction *****\n",
      "  Num examples = 806\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='117' max='101' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [101/101 00:05]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Prediction *****\n",
      "  Num examples = 64\n",
      "  Batch size = 8\n",
      "***** Running Prediction *****\n",
      "  Num examples = 59\n",
      "  Batch size = 8\n",
      "/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:309: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  FutureWarning,\n",
      "***** Running training *****\n",
      "  Num examples = 3766\n",
      "  Num Epochs = 6\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 2826\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2826' max='2826' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2826/2826 07:16, Epoch 6/6]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.275400</td>\n",
       "      <td>0.544468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.268300</td>\n",
       "      <td>0.535374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.248500</td>\n",
       "      <td>0.597350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.253400</td>\n",
       "      <td>0.608561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.234100</td>\n",
       "      <td>0.595604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.218300</td>\n",
       "      <td>0.578231</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 807\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to train_with_reg/checkpoint-471\n",
      "Configuration saved in train_with_reg/checkpoint-471/config.json\n",
      "Model weights saved in train_with_reg/checkpoint-471/pytorch_model.bin\n",
      "tokenizer config file saved in train_with_reg/checkpoint-471/tokenizer_config.json\n",
      "Special tokens file saved in train_with_reg/checkpoint-471/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 807\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to train_with_reg/checkpoint-942\n",
      "Configuration saved in train_with_reg/checkpoint-942/config.json\n",
      "Model weights saved in train_with_reg/checkpoint-942/pytorch_model.bin\n",
      "tokenizer config file saved in train_with_reg/checkpoint-942/tokenizer_config.json\n",
      "Special tokens file saved in train_with_reg/checkpoint-942/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 807\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to train_with_reg/checkpoint-1413\n",
      "Configuration saved in train_with_reg/checkpoint-1413/config.json\n",
      "Model weights saved in train_with_reg/checkpoint-1413/pytorch_model.bin\n",
      "tokenizer config file saved in train_with_reg/checkpoint-1413/tokenizer_config.json\n",
      "Special tokens file saved in train_with_reg/checkpoint-1413/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 807\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to train_with_reg/checkpoint-1884\n",
      "Configuration saved in train_with_reg/checkpoint-1884/config.json\n",
      "Model weights saved in train_with_reg/checkpoint-1884/pytorch_model.bin\n",
      "tokenizer config file saved in train_with_reg/checkpoint-1884/tokenizer_config.json\n",
      "Special tokens file saved in train_with_reg/checkpoint-1884/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 807\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to train_with_reg/checkpoint-2355\n",
      "Configuration saved in train_with_reg/checkpoint-2355/config.json\n",
      "Model weights saved in train_with_reg/checkpoint-2355/pytorch_model.bin\n",
      "tokenizer config file saved in train_with_reg/checkpoint-2355/tokenizer_config.json\n",
      "Special tokens file saved in train_with_reg/checkpoint-2355/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 807\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to train_with_reg/checkpoint-2826\n",
      "Configuration saved in train_with_reg/checkpoint-2826/config.json\n",
      "Model weights saved in train_with_reg/checkpoint-2826/pytorch_model.bin\n",
      "tokenizer config file saved in train_with_reg/checkpoint-2826/tokenizer_config.json\n",
      "Special tokens file saved in train_with_reg/checkpoint-2826/special_tokens_map.json\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Prediction *****\n",
      "  Num examples = 807\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='117' max='101' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [101/101 00:05]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Prediction *****\n",
      "  Num examples = 62\n",
      "  Batch size = 8\n",
      "***** Running Prediction *****\n",
      "  Num examples = 58\n",
      "  Batch size = 8\n",
      "/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:309: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  FutureWarning,\n",
      "***** Running training *****\n",
      "  Num examples = 3769\n",
      "  Num Epochs = 6\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 2832\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2832' max='2832' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2832/2832 07:14, Epoch 6/6]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.254000</td>\n",
       "      <td>0.554471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.243800</td>\n",
       "      <td>0.644957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.222200</td>\n",
       "      <td>0.573542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.219000</td>\n",
       "      <td>0.605869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.206300</td>\n",
       "      <td>0.650375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.195000</td>\n",
       "      <td>0.587233</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 809\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to train_with_reg/checkpoint-472\n",
      "Configuration saved in train_with_reg/checkpoint-472/config.json\n",
      "Model weights saved in train_with_reg/checkpoint-472/pytorch_model.bin\n",
      "tokenizer config file saved in train_with_reg/checkpoint-472/tokenizer_config.json\n",
      "Special tokens file saved in train_with_reg/checkpoint-472/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 809\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to train_with_reg/checkpoint-944\n",
      "Configuration saved in train_with_reg/checkpoint-944/config.json\n",
      "Model weights saved in train_with_reg/checkpoint-944/pytorch_model.bin\n",
      "tokenizer config file saved in train_with_reg/checkpoint-944/tokenizer_config.json\n",
      "Special tokens file saved in train_with_reg/checkpoint-944/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 809\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to train_with_reg/checkpoint-1416\n",
      "Configuration saved in train_with_reg/checkpoint-1416/config.json\n",
      "Model weights saved in train_with_reg/checkpoint-1416/pytorch_model.bin\n",
      "tokenizer config file saved in train_with_reg/checkpoint-1416/tokenizer_config.json\n",
      "Special tokens file saved in train_with_reg/checkpoint-1416/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 809\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to train_with_reg/checkpoint-1888\n",
      "Configuration saved in train_with_reg/checkpoint-1888/config.json\n",
      "Model weights saved in train_with_reg/checkpoint-1888/pytorch_model.bin\n",
      "tokenizer config file saved in train_with_reg/checkpoint-1888/tokenizer_config.json\n",
      "Special tokens file saved in train_with_reg/checkpoint-1888/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 809\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to train_with_reg/checkpoint-2360\n",
      "Configuration saved in train_with_reg/checkpoint-2360/config.json\n",
      "Model weights saved in train_with_reg/checkpoint-2360/pytorch_model.bin\n",
      "tokenizer config file saved in train_with_reg/checkpoint-2360/tokenizer_config.json\n",
      "Special tokens file saved in train_with_reg/checkpoint-2360/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 809\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to train_with_reg/checkpoint-2832\n",
      "Configuration saved in train_with_reg/checkpoint-2832/config.json\n",
      "Model weights saved in train_with_reg/checkpoint-2832/pytorch_model.bin\n",
      "tokenizer config file saved in train_with_reg/checkpoint-2832/tokenizer_config.json\n",
      "Special tokens file saved in train_with_reg/checkpoint-2832/special_tokens_map.json\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Prediction *****\n",
      "  Num examples = 809\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='117' max='102' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [102/102 00:05]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Prediction *****\n",
      "  Num examples = 58\n",
      "  Batch size = 8\n",
      "***** Running Prediction *****\n",
      "  Num examples = 56\n",
      "  Batch size = 8\n",
      "/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:309: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  FutureWarning,\n",
      "***** Running training *****\n",
      "  Num examples = 3766\n",
      "  Num Epochs = 6\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 2826\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2826' max='2826' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2826/2826 07:12, Epoch 6/6]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.223100</td>\n",
       "      <td>0.547777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.206100</td>\n",
       "      <td>0.645501</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.184800</td>\n",
       "      <td>0.651628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.189500</td>\n",
       "      <td>0.614323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.174900</td>\n",
       "      <td>0.590786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.172500</td>\n",
       "      <td>0.601666</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 808\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to train_with_reg/checkpoint-471\n",
      "Configuration saved in train_with_reg/checkpoint-471/config.json\n",
      "Model weights saved in train_with_reg/checkpoint-471/pytorch_model.bin\n",
      "tokenizer config file saved in train_with_reg/checkpoint-471/tokenizer_config.json\n",
      "Special tokens file saved in train_with_reg/checkpoint-471/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 808\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to train_with_reg/checkpoint-942\n",
      "Configuration saved in train_with_reg/checkpoint-942/config.json\n",
      "Model weights saved in train_with_reg/checkpoint-942/pytorch_model.bin\n",
      "tokenizer config file saved in train_with_reg/checkpoint-942/tokenizer_config.json\n",
      "Special tokens file saved in train_with_reg/checkpoint-942/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 808\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to train_with_reg/checkpoint-1413\n",
      "Configuration saved in train_with_reg/checkpoint-1413/config.json\n",
      "Model weights saved in train_with_reg/checkpoint-1413/pytorch_model.bin\n",
      "tokenizer config file saved in train_with_reg/checkpoint-1413/tokenizer_config.json\n",
      "Special tokens file saved in train_with_reg/checkpoint-1413/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 808\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to train_with_reg/checkpoint-1884\n",
      "Configuration saved in train_with_reg/checkpoint-1884/config.json\n",
      "Model weights saved in train_with_reg/checkpoint-1884/pytorch_model.bin\n",
      "tokenizer config file saved in train_with_reg/checkpoint-1884/tokenizer_config.json\n",
      "Special tokens file saved in train_with_reg/checkpoint-1884/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 808\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to train_with_reg/checkpoint-2355\n",
      "Configuration saved in train_with_reg/checkpoint-2355/config.json\n",
      "Model weights saved in train_with_reg/checkpoint-2355/pytorch_model.bin\n",
      "tokenizer config file saved in train_with_reg/checkpoint-2355/tokenizer_config.json\n",
      "Special tokens file saved in train_with_reg/checkpoint-2355/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 808\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to train_with_reg/checkpoint-2826\n",
      "Configuration saved in train_with_reg/checkpoint-2826/config.json\n",
      "Model weights saved in train_with_reg/checkpoint-2826/pytorch_model.bin\n",
      "tokenizer config file saved in train_with_reg/checkpoint-2826/tokenizer_config.json\n",
      "Special tokens file saved in train_with_reg/checkpoint-2826/special_tokens_map.json\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Prediction *****\n",
      "  Num examples = 808\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='120' max='101' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [101/101 00:05]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Prediction *****\n",
      "  Num examples = 75\n",
      "  Batch size = 8\n",
      "***** Running Prediction *****\n",
      "  Num examples = 72\n",
      "  Batch size = 8\n",
      "/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:309: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  FutureWarning,\n",
      "***** Running training *****\n",
      "  Num examples = 3766\n",
      "  Num Epochs = 6\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 2826\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2826' max='2826' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2826/2826 07:09, Epoch 6/6]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.208100</td>\n",
       "      <td>0.585860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.554162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.182000</td>\n",
       "      <td>0.587086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.173000</td>\n",
       "      <td>0.574388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.157600</td>\n",
       "      <td>0.582937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.154200</td>\n",
       "      <td>0.600029</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 809\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to train_with_reg/checkpoint-471\n",
      "Configuration saved in train_with_reg/checkpoint-471/config.json\n",
      "Model weights saved in train_with_reg/checkpoint-471/pytorch_model.bin\n",
      "tokenizer config file saved in train_with_reg/checkpoint-471/tokenizer_config.json\n",
      "Special tokens file saved in train_with_reg/checkpoint-471/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 809\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to train_with_reg/checkpoint-942\n",
      "Configuration saved in train_with_reg/checkpoint-942/config.json\n",
      "Model weights saved in train_with_reg/checkpoint-942/pytorch_model.bin\n",
      "tokenizer config file saved in train_with_reg/checkpoint-942/tokenizer_config.json\n",
      "Special tokens file saved in train_with_reg/checkpoint-942/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 809\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to train_with_reg/checkpoint-1413\n",
      "Configuration saved in train_with_reg/checkpoint-1413/config.json\n",
      "Model weights saved in train_with_reg/checkpoint-1413/pytorch_model.bin\n",
      "tokenizer config file saved in train_with_reg/checkpoint-1413/tokenizer_config.json\n",
      "Special tokens file saved in train_with_reg/checkpoint-1413/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 809\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to train_with_reg/checkpoint-1884\n",
      "Configuration saved in train_with_reg/checkpoint-1884/config.json\n",
      "Model weights saved in train_with_reg/checkpoint-1884/pytorch_model.bin\n",
      "tokenizer config file saved in train_with_reg/checkpoint-1884/tokenizer_config.json\n",
      "Special tokens file saved in train_with_reg/checkpoint-1884/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 809\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to train_with_reg/checkpoint-2355\n",
      "Configuration saved in train_with_reg/checkpoint-2355/config.json\n",
      "Model weights saved in train_with_reg/checkpoint-2355/pytorch_model.bin\n",
      "tokenizer config file saved in train_with_reg/checkpoint-2355/tokenizer_config.json\n",
      "Special tokens file saved in train_with_reg/checkpoint-2355/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 809\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to train_with_reg/checkpoint-2826\n",
      "Configuration saved in train_with_reg/checkpoint-2826/config.json\n",
      "Model weights saved in train_with_reg/checkpoint-2826/pytorch_model.bin\n",
      "tokenizer config file saved in train_with_reg/checkpoint-2826/tokenizer_config.json\n",
      "Special tokens file saved in train_with_reg/checkpoint-2826/special_tokens_map.json\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Prediction *****\n",
      "  Num examples = 809\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='119' max='102' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [102/102 00:05]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Prediction *****\n",
      "  Num examples = 66\n",
      "  Batch size = 8\n",
      "***** Running Prediction *****\n",
      "  Num examples = 64\n",
      "  Batch size = 8\n",
      "/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:309: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  FutureWarning,\n",
      "***** Running training *****\n",
      "  Num examples = 3768\n",
      "  Num Epochs = 6\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 2826\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2826' max='2826' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2826/2826 07:09, Epoch 6/6]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.171800</td>\n",
       "      <td>0.622236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.170200</td>\n",
       "      <td>0.664769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.160700</td>\n",
       "      <td>0.559964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.145400</td>\n",
       "      <td>0.572737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.144900</td>\n",
       "      <td>0.568354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.137600</td>\n",
       "      <td>0.579893</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 808\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to train_with_reg/checkpoint-471\n",
      "Configuration saved in train_with_reg/checkpoint-471/config.json\n",
      "Model weights saved in train_with_reg/checkpoint-471/pytorch_model.bin\n",
      "tokenizer config file saved in train_with_reg/checkpoint-471/tokenizer_config.json\n",
      "Special tokens file saved in train_with_reg/checkpoint-471/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 808\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to train_with_reg/checkpoint-942\n",
      "Configuration saved in train_with_reg/checkpoint-942/config.json\n",
      "Model weights saved in train_with_reg/checkpoint-942/pytorch_model.bin\n",
      "tokenizer config file saved in train_with_reg/checkpoint-942/tokenizer_config.json\n",
      "Special tokens file saved in train_with_reg/checkpoint-942/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 808\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to train_with_reg/checkpoint-1413\n",
      "Configuration saved in train_with_reg/checkpoint-1413/config.json\n",
      "Model weights saved in train_with_reg/checkpoint-1413/pytorch_model.bin\n",
      "tokenizer config file saved in train_with_reg/checkpoint-1413/tokenizer_config.json\n",
      "Special tokens file saved in train_with_reg/checkpoint-1413/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 808\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to train_with_reg/checkpoint-1884\n",
      "Configuration saved in train_with_reg/checkpoint-1884/config.json\n",
      "Model weights saved in train_with_reg/checkpoint-1884/pytorch_model.bin\n",
      "tokenizer config file saved in train_with_reg/checkpoint-1884/tokenizer_config.json\n",
      "Special tokens file saved in train_with_reg/checkpoint-1884/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 808\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to train_with_reg/checkpoint-2355\n",
      "Configuration saved in train_with_reg/checkpoint-2355/config.json\n",
      "Model weights saved in train_with_reg/checkpoint-2355/pytorch_model.bin\n",
      "tokenizer config file saved in train_with_reg/checkpoint-2355/tokenizer_config.json\n",
      "Special tokens file saved in train_with_reg/checkpoint-2355/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 808\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to train_with_reg/checkpoint-2826\n",
      "Configuration saved in train_with_reg/checkpoint-2826/config.json\n",
      "Model weights saved in train_with_reg/checkpoint-2826/pytorch_model.bin\n",
      "tokenizer config file saved in train_with_reg/checkpoint-2826/tokenizer_config.json\n",
      "Special tokens file saved in train_with_reg/checkpoint-2826/special_tokens_map.json\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Prediction *****\n",
      "  Num examples = 808\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='118' max='101' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [101/101 00:05]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Prediction *****\n",
      "  Num examples = 67\n",
      "  Batch size = 8\n",
      "***** Running Prediction *****\n",
      "  Num examples = 64\n",
      "  Batch size = 8\n",
      "/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:309: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  FutureWarning,\n",
      "***** Running training *****\n",
      "  Num examples = 3768\n",
      "  Num Epochs = 6\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 2826\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2826' max='2826' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2826/2826 07:12, Epoch 6/6]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.155000</td>\n",
       "      <td>0.569080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.148400</td>\n",
       "      <td>0.545330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.143700</td>\n",
       "      <td>0.586913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.127300</td>\n",
       "      <td>0.571189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.128200</td>\n",
       "      <td>0.577566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.114700</td>\n",
       "      <td>0.584031</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 809\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to train_with_reg/checkpoint-471\n",
      "Configuration saved in train_with_reg/checkpoint-471/config.json\n",
      "Model weights saved in train_with_reg/checkpoint-471/pytorch_model.bin\n",
      "tokenizer config file saved in train_with_reg/checkpoint-471/tokenizer_config.json\n",
      "Special tokens file saved in train_with_reg/checkpoint-471/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 809\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to train_with_reg/checkpoint-942\n",
      "Configuration saved in train_with_reg/checkpoint-942/config.json\n",
      "Model weights saved in train_with_reg/checkpoint-942/pytorch_model.bin\n",
      "tokenizer config file saved in train_with_reg/checkpoint-942/tokenizer_config.json\n",
      "Special tokens file saved in train_with_reg/checkpoint-942/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 809\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to train_with_reg/checkpoint-1413\n",
      "Configuration saved in train_with_reg/checkpoint-1413/config.json\n",
      "Model weights saved in train_with_reg/checkpoint-1413/pytorch_model.bin\n",
      "tokenizer config file saved in train_with_reg/checkpoint-1413/tokenizer_config.json\n",
      "Special tokens file saved in train_with_reg/checkpoint-1413/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 809\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to train_with_reg/checkpoint-1884\n",
      "Configuration saved in train_with_reg/checkpoint-1884/config.json\n",
      "Model weights saved in train_with_reg/checkpoint-1884/pytorch_model.bin\n",
      "tokenizer config file saved in train_with_reg/checkpoint-1884/tokenizer_config.json\n",
      "Special tokens file saved in train_with_reg/checkpoint-1884/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 809\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to train_with_reg/checkpoint-2355\n",
      "Configuration saved in train_with_reg/checkpoint-2355/config.json\n",
      "Model weights saved in train_with_reg/checkpoint-2355/pytorch_model.bin\n",
      "tokenizer config file saved in train_with_reg/checkpoint-2355/tokenizer_config.json\n",
      "Special tokens file saved in train_with_reg/checkpoint-2355/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 809\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to train_with_reg/checkpoint-2826\n",
      "Configuration saved in train_with_reg/checkpoint-2826/config.json\n",
      "Model weights saved in train_with_reg/checkpoint-2826/pytorch_model.bin\n",
      "tokenizer config file saved in train_with_reg/checkpoint-2826/tokenizer_config.json\n",
      "Special tokens file saved in train_with_reg/checkpoint-2826/special_tokens_map.json\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Prediction *****\n",
      "  Num examples = 809\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='118' max='102' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [102/102 00:05]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Prediction *****\n",
      "  Num examples = 61\n",
      "  Batch size = 8\n",
      "***** Running Prediction *****\n",
      "  Num examples = 59\n",
      "  Batch size = 8\n",
      "/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:309: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  FutureWarning,\n",
      "***** Running training *****\n",
      "  Num examples = 3764\n",
      "  Num Epochs = 6\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 2826\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2826' max='2826' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2826/2826 07:11, Epoch 6/6]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.139500</td>\n",
       "      <td>0.536382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.138200</td>\n",
       "      <td>0.586570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.123900</td>\n",
       "      <td>0.556511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.119800</td>\n",
       "      <td>0.569847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.113300</td>\n",
       "      <td>0.593525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.105100</td>\n",
       "      <td>0.578944</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 810\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to train_with_reg/checkpoint-471\n",
      "Configuration saved in train_with_reg/checkpoint-471/config.json\n",
      "Model weights saved in train_with_reg/checkpoint-471/pytorch_model.bin\n",
      "tokenizer config file saved in train_with_reg/checkpoint-471/tokenizer_config.json\n",
      "Special tokens file saved in train_with_reg/checkpoint-471/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 810\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to train_with_reg/checkpoint-942\n",
      "Configuration saved in train_with_reg/checkpoint-942/config.json\n",
      "Model weights saved in train_with_reg/checkpoint-942/pytorch_model.bin\n",
      "tokenizer config file saved in train_with_reg/checkpoint-942/tokenizer_config.json\n",
      "Special tokens file saved in train_with_reg/checkpoint-942/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 810\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to train_with_reg/checkpoint-1413\n",
      "Configuration saved in train_with_reg/checkpoint-1413/config.json\n",
      "Model weights saved in train_with_reg/checkpoint-1413/pytorch_model.bin\n",
      "tokenizer config file saved in train_with_reg/checkpoint-1413/tokenizer_config.json\n",
      "Special tokens file saved in train_with_reg/checkpoint-1413/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 810\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to train_with_reg/checkpoint-1884\n",
      "Configuration saved in train_with_reg/checkpoint-1884/config.json\n",
      "Model weights saved in train_with_reg/checkpoint-1884/pytorch_model.bin\n",
      "tokenizer config file saved in train_with_reg/checkpoint-1884/tokenizer_config.json\n",
      "Special tokens file saved in train_with_reg/checkpoint-1884/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 810\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to train_with_reg/checkpoint-2355\n",
      "Configuration saved in train_with_reg/checkpoint-2355/config.json\n",
      "Model weights saved in train_with_reg/checkpoint-2355/pytorch_model.bin\n",
      "tokenizer config file saved in train_with_reg/checkpoint-2355/tokenizer_config.json\n",
      "Special tokens file saved in train_with_reg/checkpoint-2355/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 810\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to train_with_reg/checkpoint-2826\n",
      "Configuration saved in train_with_reg/checkpoint-2826/config.json\n",
      "Model weights saved in train_with_reg/checkpoint-2826/pytorch_model.bin\n",
      "tokenizer config file saved in train_with_reg/checkpoint-2826/tokenizer_config.json\n",
      "Special tokens file saved in train_with_reg/checkpoint-2826/special_tokens_map.json\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Prediction *****\n",
      "  Num examples = 810\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='116' max='102' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [102/102 00:05]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Prediction *****\n",
      "  Num examples = 53\n",
      "  Batch size = 8\n",
      "***** Running Prediction *****\n",
      "  Num examples = 52\n",
      "  Batch size = 8\n",
      "/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:309: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  FutureWarning,\n",
      "***** Running training *****\n",
      "  Num examples = 3766\n",
      "  Num Epochs = 6\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 2826\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2826' max='2826' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2826/2826 07:10, Epoch 6/6]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.131100</td>\n",
       "      <td>0.568654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.126500</td>\n",
       "      <td>0.563903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.119600</td>\n",
       "      <td>0.582651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.110200</td>\n",
       "      <td>0.564935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.102700</td>\n",
       "      <td>0.559936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.096300</td>\n",
       "      <td>0.578250</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 807\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to train_with_reg/checkpoint-471\n",
      "Configuration saved in train_with_reg/checkpoint-471/config.json\n",
      "Model weights saved in train_with_reg/checkpoint-471/pytorch_model.bin\n",
      "tokenizer config file saved in train_with_reg/checkpoint-471/tokenizer_config.json\n",
      "Special tokens file saved in train_with_reg/checkpoint-471/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 807\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to train_with_reg/checkpoint-942\n",
      "Configuration saved in train_with_reg/checkpoint-942/config.json\n",
      "Model weights saved in train_with_reg/checkpoint-942/pytorch_model.bin\n",
      "tokenizer config file saved in train_with_reg/checkpoint-942/tokenizer_config.json\n",
      "Special tokens file saved in train_with_reg/checkpoint-942/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 807\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to train_with_reg/checkpoint-1413\n",
      "Configuration saved in train_with_reg/checkpoint-1413/config.json\n",
      "Model weights saved in train_with_reg/checkpoint-1413/pytorch_model.bin\n",
      "tokenizer config file saved in train_with_reg/checkpoint-1413/tokenizer_config.json\n",
      "Special tokens file saved in train_with_reg/checkpoint-1413/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 807\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to train_with_reg/checkpoint-1884\n",
      "Configuration saved in train_with_reg/checkpoint-1884/config.json\n",
      "Model weights saved in train_with_reg/checkpoint-1884/pytorch_model.bin\n",
      "tokenizer config file saved in train_with_reg/checkpoint-1884/tokenizer_config.json\n",
      "Special tokens file saved in train_with_reg/checkpoint-1884/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 807\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to train_with_reg/checkpoint-2355\n",
      "Configuration saved in train_with_reg/checkpoint-2355/config.json\n",
      "Model weights saved in train_with_reg/checkpoint-2355/pytorch_model.bin\n",
      "tokenizer config file saved in train_with_reg/checkpoint-2355/tokenizer_config.json\n",
      "Special tokens file saved in train_with_reg/checkpoint-2355/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 807\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to train_with_reg/checkpoint-2826\n",
      "Configuration saved in train_with_reg/checkpoint-2826/config.json\n",
      "Model weights saved in train_with_reg/checkpoint-2826/pytorch_model.bin\n",
      "tokenizer config file saved in train_with_reg/checkpoint-2826/tokenizer_config.json\n",
      "Special tokens file saved in train_with_reg/checkpoint-2826/special_tokens_map.json\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Prediction *****\n",
      "  Num examples = 807\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='119' max='101' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [101/101 00:05]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Prediction *****\n",
      "  Num examples = 71\n",
      "  Batch size = 8\n",
      "***** Running Prediction *****\n",
      "  Num examples = 67\n",
      "  Batch size = 8\n",
      "/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:309: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  FutureWarning,\n",
      "***** Running training *****\n",
      "  Num examples = 3768\n",
      "  Num Epochs = 6\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 2826\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2826' max='2826' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2826/2826 07:09, Epoch 6/6]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.114000</td>\n",
       "      <td>0.552947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.105400</td>\n",
       "      <td>0.586379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.108900</td>\n",
       "      <td>0.551119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.099500</td>\n",
       "      <td>0.591356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.101000</td>\n",
       "      <td>0.579090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.091100</td>\n",
       "      <td>0.578367</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 807\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to train_with_reg/checkpoint-471\n",
      "Configuration saved in train_with_reg/checkpoint-471/config.json\n",
      "Model weights saved in train_with_reg/checkpoint-471/pytorch_model.bin\n",
      "tokenizer config file saved in train_with_reg/checkpoint-471/tokenizer_config.json\n",
      "Special tokens file saved in train_with_reg/checkpoint-471/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 807\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to train_with_reg/checkpoint-942\n",
      "Configuration saved in train_with_reg/checkpoint-942/config.json\n",
      "Model weights saved in train_with_reg/checkpoint-942/pytorch_model.bin\n",
      "tokenizer config file saved in train_with_reg/checkpoint-942/tokenizer_config.json\n",
      "Special tokens file saved in train_with_reg/checkpoint-942/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 807\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to train_with_reg/checkpoint-1413\n",
      "Configuration saved in train_with_reg/checkpoint-1413/config.json\n",
      "Model weights saved in train_with_reg/checkpoint-1413/pytorch_model.bin\n",
      "tokenizer config file saved in train_with_reg/checkpoint-1413/tokenizer_config.json\n",
      "Special tokens file saved in train_with_reg/checkpoint-1413/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 807\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to train_with_reg/checkpoint-1884\n",
      "Configuration saved in train_with_reg/checkpoint-1884/config.json\n",
      "Model weights saved in train_with_reg/checkpoint-1884/pytorch_model.bin\n",
      "tokenizer config file saved in train_with_reg/checkpoint-1884/tokenizer_config.json\n",
      "Special tokens file saved in train_with_reg/checkpoint-1884/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 807\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to train_with_reg/checkpoint-2355\n",
      "Configuration saved in train_with_reg/checkpoint-2355/config.json\n",
      "Model weights saved in train_with_reg/checkpoint-2355/pytorch_model.bin\n",
      "tokenizer config file saved in train_with_reg/checkpoint-2355/tokenizer_config.json\n",
      "Special tokens file saved in train_with_reg/checkpoint-2355/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 807\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to train_with_reg/checkpoint-2826\n",
      "Configuration saved in train_with_reg/checkpoint-2826/config.json\n",
      "Model weights saved in train_with_reg/checkpoint-2826/pytorch_model.bin\n",
      "tokenizer config file saved in train_with_reg/checkpoint-2826/tokenizer_config.json\n",
      "Special tokens file saved in train_with_reg/checkpoint-2826/special_tokens_map.json\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Prediction *****\n",
      "  Num examples = 807\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='119' max='101' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [101/101 00:05]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Prediction *****\n",
      "  Num examples = 71\n",
      "  Batch size = 8\n",
      "***** Running Prediction *****\n",
      "  Num examples = 67\n",
      "  Batch size = 8\n",
      "/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:309: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  FutureWarning,\n",
      "***** Running training *****\n",
      "  Num examples = 3767\n",
      "  Num Epochs = 6\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 2826\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2826' max='2826' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2826/2826 07:12, Epoch 6/6]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.106000</td>\n",
       "      <td>0.583118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.093000</td>\n",
       "      <td>0.583723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.092300</td>\n",
       "      <td>0.568207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.087000</td>\n",
       "      <td>0.561579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.084200</td>\n",
       "      <td>0.566416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.075500</td>\n",
       "      <td>0.567159</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 810\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to train_with_reg/checkpoint-471\n",
      "Configuration saved in train_with_reg/checkpoint-471/config.json\n",
      "Model weights saved in train_with_reg/checkpoint-471/pytorch_model.bin\n",
      "tokenizer config file saved in train_with_reg/checkpoint-471/tokenizer_config.json\n",
      "Special tokens file saved in train_with_reg/checkpoint-471/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 810\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to train_with_reg/checkpoint-942\n",
      "Configuration saved in train_with_reg/checkpoint-942/config.json\n",
      "Model weights saved in train_with_reg/checkpoint-942/pytorch_model.bin\n",
      "tokenizer config file saved in train_with_reg/checkpoint-942/tokenizer_config.json\n",
      "Special tokens file saved in train_with_reg/checkpoint-942/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 810\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to train_with_reg/checkpoint-1413\n",
      "Configuration saved in train_with_reg/checkpoint-1413/config.json\n",
      "Model weights saved in train_with_reg/checkpoint-1413/pytorch_model.bin\n",
      "tokenizer config file saved in train_with_reg/checkpoint-1413/tokenizer_config.json\n",
      "Special tokens file saved in train_with_reg/checkpoint-1413/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 810\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to train_with_reg/checkpoint-1884\n",
      "Configuration saved in train_with_reg/checkpoint-1884/config.json\n",
      "Model weights saved in train_with_reg/checkpoint-1884/pytorch_model.bin\n",
      "tokenizer config file saved in train_with_reg/checkpoint-1884/tokenizer_config.json\n",
      "Special tokens file saved in train_with_reg/checkpoint-1884/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 810\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to train_with_reg/checkpoint-2355\n",
      "Configuration saved in train_with_reg/checkpoint-2355/config.json\n",
      "Model weights saved in train_with_reg/checkpoint-2355/pytorch_model.bin\n",
      "tokenizer config file saved in train_with_reg/checkpoint-2355/tokenizer_config.json\n",
      "Special tokens file saved in train_with_reg/checkpoint-2355/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 810\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to train_with_reg/checkpoint-2826\n",
      "Configuration saved in train_with_reg/checkpoint-2826/config.json\n",
      "Model weights saved in train_with_reg/checkpoint-2826/pytorch_model.bin\n",
      "tokenizer config file saved in train_with_reg/checkpoint-2826/tokenizer_config.json\n",
      "Special tokens file saved in train_with_reg/checkpoint-2826/special_tokens_map.json\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Prediction *****\n",
      "  Num examples = 810\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='118' max='102' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [102/102 00:05]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Prediction *****\n",
      "  Num examples = 63\n",
      "  Batch size = 8\n",
      "***** Running Prediction *****\n",
      "  Num examples = 62\n",
      "  Batch size = 8\n",
      "/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:309: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  FutureWarning,\n",
      "***** Running training *****\n",
      "  Num examples = 3765\n",
      "  Num Epochs = 6\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 2826\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2826' max='2826' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2826/2826 07:09, Epoch 6/6]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.091500</td>\n",
       "      <td>0.608480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.087400</td>\n",
       "      <td>0.559127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.084200</td>\n",
       "      <td>0.573620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.075700</td>\n",
       "      <td>0.579810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.075700</td>\n",
       "      <td>0.575043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.067600</td>\n",
       "      <td>0.582493</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 810\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to train_with_reg/checkpoint-471\n",
      "Configuration saved in train_with_reg/checkpoint-471/config.json\n",
      "Model weights saved in train_with_reg/checkpoint-471/pytorch_model.bin\n",
      "tokenizer config file saved in train_with_reg/checkpoint-471/tokenizer_config.json\n",
      "Special tokens file saved in train_with_reg/checkpoint-471/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 810\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to train_with_reg/checkpoint-942\n",
      "Configuration saved in train_with_reg/checkpoint-942/config.json\n",
      "Model weights saved in train_with_reg/checkpoint-942/pytorch_model.bin\n",
      "tokenizer config file saved in train_with_reg/checkpoint-942/tokenizer_config.json\n",
      "Special tokens file saved in train_with_reg/checkpoint-942/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 810\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to train_with_reg/checkpoint-1413\n",
      "Configuration saved in train_with_reg/checkpoint-1413/config.json\n",
      "Model weights saved in train_with_reg/checkpoint-1413/pytorch_model.bin\n",
      "tokenizer config file saved in train_with_reg/checkpoint-1413/tokenizer_config.json\n",
      "Special tokens file saved in train_with_reg/checkpoint-1413/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 810\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to train_with_reg/checkpoint-1884\n",
      "Configuration saved in train_with_reg/checkpoint-1884/config.json\n",
      "Model weights saved in train_with_reg/checkpoint-1884/pytorch_model.bin\n",
      "tokenizer config file saved in train_with_reg/checkpoint-1884/tokenizer_config.json\n",
      "Special tokens file saved in train_with_reg/checkpoint-1884/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 810\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to train_with_reg/checkpoint-2355\n",
      "Configuration saved in train_with_reg/checkpoint-2355/config.json\n",
      "Model weights saved in train_with_reg/checkpoint-2355/pytorch_model.bin\n",
      "tokenizer config file saved in train_with_reg/checkpoint-2355/tokenizer_config.json\n",
      "Special tokens file saved in train_with_reg/checkpoint-2355/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 810\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to train_with_reg/checkpoint-2826\n",
      "Configuration saved in train_with_reg/checkpoint-2826/config.json\n",
      "Model weights saved in train_with_reg/checkpoint-2826/pytorch_model.bin\n",
      "tokenizer config file saved in train_with_reg/checkpoint-2826/tokenizer_config.json\n",
      "Special tokens file saved in train_with_reg/checkpoint-2826/special_tokens_map.json\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Prediction *****\n",
      "  Num examples = 810\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='122' max='102' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [102/102 00:05]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Prediction *****\n",
      "  Num examples = 76\n",
      "  Batch size = 8\n",
      "***** Running Prediction *****\n",
      "  Num examples = 75\n",
      "  Batch size = 8\n",
      "/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:309: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  FutureWarning,\n",
      "***** Running training *****\n",
      "  Num examples = 3766\n",
      "  Num Epochs = 6\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 2826\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2826' max='2826' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2826/2826 07:09, Epoch 6/6]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.086900</td>\n",
       "      <td>0.588406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.083700</td>\n",
       "      <td>0.587392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.076900</td>\n",
       "      <td>0.599917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.069800</td>\n",
       "      <td>0.590533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.068000</td>\n",
       "      <td>0.577069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.063200</td>\n",
       "      <td>0.583316</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 808\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to train_with_reg/checkpoint-471\n",
      "Configuration saved in train_with_reg/checkpoint-471/config.json\n",
      "Model weights saved in train_with_reg/checkpoint-471/pytorch_model.bin\n",
      "tokenizer config file saved in train_with_reg/checkpoint-471/tokenizer_config.json\n",
      "Special tokens file saved in train_with_reg/checkpoint-471/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 808\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to train_with_reg/checkpoint-942\n",
      "Configuration saved in train_with_reg/checkpoint-942/config.json\n",
      "Model weights saved in train_with_reg/checkpoint-942/pytorch_model.bin\n",
      "tokenizer config file saved in train_with_reg/checkpoint-942/tokenizer_config.json\n",
      "Special tokens file saved in train_with_reg/checkpoint-942/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 808\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to train_with_reg/checkpoint-1413\n",
      "Configuration saved in train_with_reg/checkpoint-1413/config.json\n",
      "Model weights saved in train_with_reg/checkpoint-1413/pytorch_model.bin\n",
      "tokenizer config file saved in train_with_reg/checkpoint-1413/tokenizer_config.json\n",
      "Special tokens file saved in train_with_reg/checkpoint-1413/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 808\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to train_with_reg/checkpoint-1884\n",
      "Configuration saved in train_with_reg/checkpoint-1884/config.json\n",
      "Model weights saved in train_with_reg/checkpoint-1884/pytorch_model.bin\n",
      "tokenizer config file saved in train_with_reg/checkpoint-1884/tokenizer_config.json\n",
      "Special tokens file saved in train_with_reg/checkpoint-1884/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 808\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to train_with_reg/checkpoint-2355\n",
      "Configuration saved in train_with_reg/checkpoint-2355/config.json\n",
      "Model weights saved in train_with_reg/checkpoint-2355/pytorch_model.bin\n",
      "tokenizer config file saved in train_with_reg/checkpoint-2355/tokenizer_config.json\n",
      "Special tokens file saved in train_with_reg/checkpoint-2355/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 808\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to train_with_reg/checkpoint-2826\n",
      "Configuration saved in train_with_reg/checkpoint-2826/config.json\n",
      "Model weights saved in train_with_reg/checkpoint-2826/pytorch_model.bin\n",
      "tokenizer config file saved in train_with_reg/checkpoint-2826/tokenizer_config.json\n",
      "Special tokens file saved in train_with_reg/checkpoint-2826/special_tokens_map.json\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Prediction *****\n",
      "  Num examples = 808\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='117' max='101' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [101/101 00:05]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Prediction *****\n",
      "  Num examples = 63\n",
      "  Batch size = 8\n",
      "***** Running Prediction *****\n",
      "  Num examples = 60\n",
      "  Batch size = 8\n",
      "/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:309: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  FutureWarning,\n",
      "***** Running training *****\n",
      "  Num examples = 3766\n",
      "  Num Epochs = 6\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 2826\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2826' max='2826' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2826/2826 07:10, Epoch 6/6]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.078000</td>\n",
       "      <td>0.584835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.078400</td>\n",
       "      <td>0.561321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.067600</td>\n",
       "      <td>0.593662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.068700</td>\n",
       "      <td>0.564559</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.063700</td>\n",
       "      <td>0.556320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.058300</td>\n",
       "      <td>0.562295</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 807\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to train_with_reg/checkpoint-471\n",
      "Configuration saved in train_with_reg/checkpoint-471/config.json\n",
      "Model weights saved in train_with_reg/checkpoint-471/pytorch_model.bin\n",
      "tokenizer config file saved in train_with_reg/checkpoint-471/tokenizer_config.json\n",
      "Special tokens file saved in train_with_reg/checkpoint-471/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 807\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to train_with_reg/checkpoint-942\n",
      "Configuration saved in train_with_reg/checkpoint-942/config.json\n",
      "Model weights saved in train_with_reg/checkpoint-942/pytorch_model.bin\n",
      "tokenizer config file saved in train_with_reg/checkpoint-942/tokenizer_config.json\n",
      "Special tokens file saved in train_with_reg/checkpoint-942/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 807\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to train_with_reg/checkpoint-1413\n",
      "Configuration saved in train_with_reg/checkpoint-1413/config.json\n",
      "Model weights saved in train_with_reg/checkpoint-1413/pytorch_model.bin\n",
      "tokenizer config file saved in train_with_reg/checkpoint-1413/tokenizer_config.json\n",
      "Special tokens file saved in train_with_reg/checkpoint-1413/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 807\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to train_with_reg/checkpoint-1884\n",
      "Configuration saved in train_with_reg/checkpoint-1884/config.json\n",
      "Model weights saved in train_with_reg/checkpoint-1884/pytorch_model.bin\n",
      "tokenizer config file saved in train_with_reg/checkpoint-1884/tokenizer_config.json\n",
      "Special tokens file saved in train_with_reg/checkpoint-1884/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 807\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to train_with_reg/checkpoint-2355\n",
      "Configuration saved in train_with_reg/checkpoint-2355/config.json\n",
      "Model weights saved in train_with_reg/checkpoint-2355/pytorch_model.bin\n",
      "tokenizer config file saved in train_with_reg/checkpoint-2355/tokenizer_config.json\n",
      "Special tokens file saved in train_with_reg/checkpoint-2355/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 807\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to train_with_reg/checkpoint-2826\n",
      "Configuration saved in train_with_reg/checkpoint-2826/config.json\n",
      "Model weights saved in train_with_reg/checkpoint-2826/pytorch_model.bin\n",
      "tokenizer config file saved in train_with_reg/checkpoint-2826/tokenizer_config.json\n",
      "Special tokens file saved in train_with_reg/checkpoint-2826/special_tokens_map.json\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Prediction *****\n",
      "  Num examples = 807\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='116' max='101' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [101/101 00:05]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Prediction *****\n",
      "  Num examples = 58\n",
      "  Batch size = 8\n",
      "***** Running Prediction *****\n",
      "  Num examples = 54\n",
      "  Batch size = 8\n",
      "/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:309: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  FutureWarning,\n",
      "***** Running training *****\n",
      "  Num examples = 3765\n",
      "  Num Epochs = 6\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 2826\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2826' max='2826' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2826/2826 07:11, Epoch 6/6]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.084200</td>\n",
       "      <td>0.572361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.081200</td>\n",
       "      <td>0.551701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.076500</td>\n",
       "      <td>0.564494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.072600</td>\n",
       "      <td>0.557411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.065000</td>\n",
       "      <td>0.544428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.063800</td>\n",
       "      <td>0.553287</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 809\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to train_with_reg/checkpoint-471\n",
      "Configuration saved in train_with_reg/checkpoint-471/config.json\n",
      "Model weights saved in train_with_reg/checkpoint-471/pytorch_model.bin\n",
      "tokenizer config file saved in train_with_reg/checkpoint-471/tokenizer_config.json\n",
      "Special tokens file saved in train_with_reg/checkpoint-471/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 809\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to train_with_reg/checkpoint-942\n",
      "Configuration saved in train_with_reg/checkpoint-942/config.json\n",
      "Model weights saved in train_with_reg/checkpoint-942/pytorch_model.bin\n",
      "tokenizer config file saved in train_with_reg/checkpoint-942/tokenizer_config.json\n",
      "Special tokens file saved in train_with_reg/checkpoint-942/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 809\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to train_with_reg/checkpoint-1413\n",
      "Configuration saved in train_with_reg/checkpoint-1413/config.json\n",
      "Model weights saved in train_with_reg/checkpoint-1413/pytorch_model.bin\n",
      "tokenizer config file saved in train_with_reg/checkpoint-1413/tokenizer_config.json\n",
      "Special tokens file saved in train_with_reg/checkpoint-1413/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 809\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to train_with_reg/checkpoint-1884\n",
      "Configuration saved in train_with_reg/checkpoint-1884/config.json\n",
      "Model weights saved in train_with_reg/checkpoint-1884/pytorch_model.bin\n",
      "tokenizer config file saved in train_with_reg/checkpoint-1884/tokenizer_config.json\n",
      "Special tokens file saved in train_with_reg/checkpoint-1884/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 809\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to train_with_reg/checkpoint-2355\n",
      "Configuration saved in train_with_reg/checkpoint-2355/config.json\n",
      "Model weights saved in train_with_reg/checkpoint-2355/pytorch_model.bin\n",
      "tokenizer config file saved in train_with_reg/checkpoint-2355/tokenizer_config.json\n",
      "Special tokens file saved in train_with_reg/checkpoint-2355/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 809\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to train_with_reg/checkpoint-2826\n",
      "Configuration saved in train_with_reg/checkpoint-2826/config.json\n",
      "Model weights saved in train_with_reg/checkpoint-2826/pytorch_model.bin\n",
      "tokenizer config file saved in train_with_reg/checkpoint-2826/tokenizer_config.json\n",
      "Special tokens file saved in train_with_reg/checkpoint-2826/special_tokens_map.json\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Prediction *****\n",
      "  Num examples = 809\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='118' max='102' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [102/102 00:05]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Prediction *****\n",
      "  Num examples = 63\n",
      "  Batch size = 8\n",
      "***** Running Prediction *****\n",
      "  Num examples = 61\n",
      "  Batch size = 8\n",
      "/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:309: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  FutureWarning,\n",
      "***** Running training *****\n",
      "  Num examples = 3768\n",
      "  Num Epochs = 6\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 2826\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2826' max='2826' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2826/2826 07:11, Epoch 6/6]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.087900</td>\n",
       "      <td>0.528837</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.084600</td>\n",
       "      <td>0.531312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.076600</td>\n",
       "      <td>0.538866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.070100</td>\n",
       "      <td>0.539375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.067400</td>\n",
       "      <td>0.534813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.062500</td>\n",
       "      <td>0.531697</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 809\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to train_with_reg/checkpoint-471\n",
      "Configuration saved in train_with_reg/checkpoint-471/config.json\n",
      "Model weights saved in train_with_reg/checkpoint-471/pytorch_model.bin\n",
      "tokenizer config file saved in train_with_reg/checkpoint-471/tokenizer_config.json\n",
      "Special tokens file saved in train_with_reg/checkpoint-471/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 809\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to train_with_reg/checkpoint-942\n",
      "Configuration saved in train_with_reg/checkpoint-942/config.json\n",
      "Model weights saved in train_with_reg/checkpoint-942/pytorch_model.bin\n",
      "tokenizer config file saved in train_with_reg/checkpoint-942/tokenizer_config.json\n",
      "Special tokens file saved in train_with_reg/checkpoint-942/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 809\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to train_with_reg/checkpoint-1413\n",
      "Configuration saved in train_with_reg/checkpoint-1413/config.json\n",
      "Model weights saved in train_with_reg/checkpoint-1413/pytorch_model.bin\n",
      "tokenizer config file saved in train_with_reg/checkpoint-1413/tokenizer_config.json\n",
      "Special tokens file saved in train_with_reg/checkpoint-1413/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 809\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to train_with_reg/checkpoint-1884\n",
      "Configuration saved in train_with_reg/checkpoint-1884/config.json\n",
      "Model weights saved in train_with_reg/checkpoint-1884/pytorch_model.bin\n",
      "tokenizer config file saved in train_with_reg/checkpoint-1884/tokenizer_config.json\n",
      "Special tokens file saved in train_with_reg/checkpoint-1884/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 809\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to train_with_reg/checkpoint-2355\n",
      "Configuration saved in train_with_reg/checkpoint-2355/config.json\n",
      "Model weights saved in train_with_reg/checkpoint-2355/pytorch_model.bin\n",
      "tokenizer config file saved in train_with_reg/checkpoint-2355/tokenizer_config.json\n",
      "Special tokens file saved in train_with_reg/checkpoint-2355/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 809\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to train_with_reg/checkpoint-2826\n",
      "Configuration saved in train_with_reg/checkpoint-2826/config.json\n",
      "Model weights saved in train_with_reg/checkpoint-2826/pytorch_model.bin\n",
      "tokenizer config file saved in train_with_reg/checkpoint-2826/tokenizer_config.json\n",
      "Special tokens file saved in train_with_reg/checkpoint-2826/special_tokens_map.json\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Prediction *****\n",
      "  Num examples = 809\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='120' max='102' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [102/102 00:05]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Prediction *****\n",
      "  Num examples = 69\n",
      "  Batch size = 8\n",
      "***** Running Prediction *****\n",
      "  Num examples = 67\n",
      "  Batch size = 8\n",
      "/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:309: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  FutureWarning,\n",
      "***** Running training *****\n",
      "  Num examples = 3763\n",
      "  Num Epochs = 6\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 2826\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2826' max='2826' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2826/2826 07:12, Epoch 6/6]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.068100</td>\n",
       "      <td>0.571840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.062200</td>\n",
       "      <td>0.577075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.062400</td>\n",
       "      <td>0.583057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.058700</td>\n",
       "      <td>0.570075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.054000</td>\n",
       "      <td>0.567426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.049300</td>\n",
       "      <td>0.567300</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 811\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to train_with_reg/checkpoint-471\n",
      "Configuration saved in train_with_reg/checkpoint-471/config.json\n",
      "Model weights saved in train_with_reg/checkpoint-471/pytorch_model.bin\n",
      "tokenizer config file saved in train_with_reg/checkpoint-471/tokenizer_config.json\n",
      "Special tokens file saved in train_with_reg/checkpoint-471/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 811\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to train_with_reg/checkpoint-942\n",
      "Configuration saved in train_with_reg/checkpoint-942/config.json\n",
      "Model weights saved in train_with_reg/checkpoint-942/pytorch_model.bin\n",
      "tokenizer config file saved in train_with_reg/checkpoint-942/tokenizer_config.json\n",
      "Special tokens file saved in train_with_reg/checkpoint-942/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 811\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to train_with_reg/checkpoint-1413\n",
      "Configuration saved in train_with_reg/checkpoint-1413/config.json\n",
      "Model weights saved in train_with_reg/checkpoint-1413/pytorch_model.bin\n",
      "tokenizer config file saved in train_with_reg/checkpoint-1413/tokenizer_config.json\n",
      "Special tokens file saved in train_with_reg/checkpoint-1413/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 811\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to train_with_reg/checkpoint-1884\n",
      "Configuration saved in train_with_reg/checkpoint-1884/config.json\n",
      "Model weights saved in train_with_reg/checkpoint-1884/pytorch_model.bin\n",
      "tokenizer config file saved in train_with_reg/checkpoint-1884/tokenizer_config.json\n",
      "Special tokens file saved in train_with_reg/checkpoint-1884/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 811\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to train_with_reg/checkpoint-2355\n",
      "Configuration saved in train_with_reg/checkpoint-2355/config.json\n",
      "Model weights saved in train_with_reg/checkpoint-2355/pytorch_model.bin\n",
      "tokenizer config file saved in train_with_reg/checkpoint-2355/tokenizer_config.json\n",
      "Special tokens file saved in train_with_reg/checkpoint-2355/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 811\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to train_with_reg/checkpoint-2826\n",
      "Configuration saved in train_with_reg/checkpoint-2826/config.json\n",
      "Model weights saved in train_with_reg/checkpoint-2826/pytorch_model.bin\n",
      "tokenizer config file saved in train_with_reg/checkpoint-2826/tokenizer_config.json\n",
      "Special tokens file saved in train_with_reg/checkpoint-2826/special_tokens_map.json\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Prediction *****\n",
      "  Num examples = 811\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='120' max='102' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [102/102 00:05]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Prediction *****\n",
      "  Num examples = 65\n",
      "  Batch size = 8\n",
      "***** Running Prediction *****\n",
      "  Num examples = 65\n",
      "  Batch size = 8\n",
      "/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:309: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  FutureWarning,\n",
      "***** Running training *****\n",
      "  Num examples = 3770\n",
      "  Num Epochs = 6\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 2832\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2832' max='2832' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2832/2832 07:10, Epoch 6/6]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.080100</td>\n",
       "      <td>0.529110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.076400</td>\n",
       "      <td>0.561423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.073800</td>\n",
       "      <td>0.559031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.062600</td>\n",
       "      <td>0.543688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.058700</td>\n",
       "      <td>0.551814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.056100</td>\n",
       "      <td>0.544993</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 806\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to train_with_reg/checkpoint-472\n",
      "Configuration saved in train_with_reg/checkpoint-472/config.json\n",
      "Model weights saved in train_with_reg/checkpoint-472/pytorch_model.bin\n",
      "tokenizer config file saved in train_with_reg/checkpoint-472/tokenizer_config.json\n",
      "Special tokens file saved in train_with_reg/checkpoint-472/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 806\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to train_with_reg/checkpoint-944\n",
      "Configuration saved in train_with_reg/checkpoint-944/config.json\n",
      "Model weights saved in train_with_reg/checkpoint-944/pytorch_model.bin\n",
      "tokenizer config file saved in train_with_reg/checkpoint-944/tokenizer_config.json\n",
      "Special tokens file saved in train_with_reg/checkpoint-944/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 806\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to train_with_reg/checkpoint-1416\n",
      "Configuration saved in train_with_reg/checkpoint-1416/config.json\n",
      "Model weights saved in train_with_reg/checkpoint-1416/pytorch_model.bin\n",
      "tokenizer config file saved in train_with_reg/checkpoint-1416/tokenizer_config.json\n",
      "Special tokens file saved in train_with_reg/checkpoint-1416/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 806\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to train_with_reg/checkpoint-1888\n",
      "Configuration saved in train_with_reg/checkpoint-1888/config.json\n",
      "Model weights saved in train_with_reg/checkpoint-1888/pytorch_model.bin\n",
      "tokenizer config file saved in train_with_reg/checkpoint-1888/tokenizer_config.json\n",
      "Special tokens file saved in train_with_reg/checkpoint-1888/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 806\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to train_with_reg/checkpoint-2360\n",
      "Configuration saved in train_with_reg/checkpoint-2360/config.json\n",
      "Model weights saved in train_with_reg/checkpoint-2360/pytorch_model.bin\n",
      "tokenizer config file saved in train_with_reg/checkpoint-2360/tokenizer_config.json\n",
      "Special tokens file saved in train_with_reg/checkpoint-2360/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 806\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to train_with_reg/checkpoint-2832\n",
      "Configuration saved in train_with_reg/checkpoint-2832/config.json\n",
      "Model weights saved in train_with_reg/checkpoint-2832/pytorch_model.bin\n",
      "tokenizer config file saved in train_with_reg/checkpoint-2832/tokenizer_config.json\n",
      "Special tokens file saved in train_with_reg/checkpoint-2832/special_tokens_map.json\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Prediction *****\n",
      "  Num examples = 806\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='117' max='101' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [101/101 00:05]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Prediction *****\n",
      "  Num examples = 64\n",
      "  Batch size = 8\n",
      "***** Running Prediction *****\n",
      "  Num examples = 59\n",
      "  Batch size = 8\n",
      "/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:309: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  FutureWarning,\n",
      "***** Running training *****\n",
      "  Num examples = 3766\n",
      "  Num Epochs = 6\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 2826\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2826' max='2826' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2826/2826 07:10, Epoch 6/6]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.063700</td>\n",
       "      <td>0.556437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.058400</td>\n",
       "      <td>0.557954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.057000</td>\n",
       "      <td>0.567482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.054200</td>\n",
       "      <td>0.542176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.049200</td>\n",
       "      <td>0.543226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.047000</td>\n",
       "      <td>0.550999</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 807\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to train_with_reg/checkpoint-471\n",
      "Configuration saved in train_with_reg/checkpoint-471/config.json\n",
      "Model weights saved in train_with_reg/checkpoint-471/pytorch_model.bin\n",
      "tokenizer config file saved in train_with_reg/checkpoint-471/tokenizer_config.json\n",
      "Special tokens file saved in train_with_reg/checkpoint-471/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 807\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to train_with_reg/checkpoint-942\n",
      "Configuration saved in train_with_reg/checkpoint-942/config.json\n",
      "Model weights saved in train_with_reg/checkpoint-942/pytorch_model.bin\n",
      "tokenizer config file saved in train_with_reg/checkpoint-942/tokenizer_config.json\n",
      "Special tokens file saved in train_with_reg/checkpoint-942/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 807\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to train_with_reg/checkpoint-1413\n",
      "Configuration saved in train_with_reg/checkpoint-1413/config.json\n",
      "Model weights saved in train_with_reg/checkpoint-1413/pytorch_model.bin\n",
      "tokenizer config file saved in train_with_reg/checkpoint-1413/tokenizer_config.json\n",
      "Special tokens file saved in train_with_reg/checkpoint-1413/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 807\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to train_with_reg/checkpoint-1884\n",
      "Configuration saved in train_with_reg/checkpoint-1884/config.json\n",
      "Model weights saved in train_with_reg/checkpoint-1884/pytorch_model.bin\n",
      "tokenizer config file saved in train_with_reg/checkpoint-1884/tokenizer_config.json\n",
      "Special tokens file saved in train_with_reg/checkpoint-1884/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 807\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to train_with_reg/checkpoint-2355\n",
      "Configuration saved in train_with_reg/checkpoint-2355/config.json\n",
      "Model weights saved in train_with_reg/checkpoint-2355/pytorch_model.bin\n",
      "tokenizer config file saved in train_with_reg/checkpoint-2355/tokenizer_config.json\n",
      "Special tokens file saved in train_with_reg/checkpoint-2355/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 807\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to train_with_reg/checkpoint-2826\n",
      "Configuration saved in train_with_reg/checkpoint-2826/config.json\n",
      "Model weights saved in train_with_reg/checkpoint-2826/pytorch_model.bin\n",
      "tokenizer config file saved in train_with_reg/checkpoint-2826/tokenizer_config.json\n",
      "Special tokens file saved in train_with_reg/checkpoint-2826/special_tokens_map.json\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Prediction *****\n",
      "  Num examples = 807\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='116' max='101' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [101/101 00:05]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Prediction *****\n",
      "  Num examples = 59\n",
      "  Batch size = 8\n",
      "***** Running Prediction *****\n",
      "  Num examples = 55\n",
      "  Batch size = 8\n",
      "/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:309: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  FutureWarning,\n",
      "***** Running training *****\n",
      "  Num examples = 3767\n",
      "  Num Epochs = 6\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 2826\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2826' max='2826' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2826/2826 07:09, Epoch 6/6]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.068600</td>\n",
       "      <td>0.591635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.063200</td>\n",
       "      <td>0.583428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.059400</td>\n",
       "      <td>0.571776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.058600</td>\n",
       "      <td>0.566547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.054400</td>\n",
       "      <td>0.563942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.049700</td>\n",
       "      <td>0.563817</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 807\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to train_with_reg/checkpoint-471\n",
      "Configuration saved in train_with_reg/checkpoint-471/config.json\n",
      "Model weights saved in train_with_reg/checkpoint-471/pytorch_model.bin\n",
      "tokenizer config file saved in train_with_reg/checkpoint-471/tokenizer_config.json\n",
      "Special tokens file saved in train_with_reg/checkpoint-471/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 807\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to train_with_reg/checkpoint-942\n",
      "Configuration saved in train_with_reg/checkpoint-942/config.json\n",
      "Model weights saved in train_with_reg/checkpoint-942/pytorch_model.bin\n",
      "tokenizer config file saved in train_with_reg/checkpoint-942/tokenizer_config.json\n",
      "Special tokens file saved in train_with_reg/checkpoint-942/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 807\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to train_with_reg/checkpoint-1413\n",
      "Configuration saved in train_with_reg/checkpoint-1413/config.json\n",
      "Model weights saved in train_with_reg/checkpoint-1413/pytorch_model.bin\n",
      "tokenizer config file saved in train_with_reg/checkpoint-1413/tokenizer_config.json\n",
      "Special tokens file saved in train_with_reg/checkpoint-1413/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 807\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to train_with_reg/checkpoint-1884\n",
      "Configuration saved in train_with_reg/checkpoint-1884/config.json\n",
      "Model weights saved in train_with_reg/checkpoint-1884/pytorch_model.bin\n",
      "tokenizer config file saved in train_with_reg/checkpoint-1884/tokenizer_config.json\n",
      "Special tokens file saved in train_with_reg/checkpoint-1884/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 807\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to train_with_reg/checkpoint-2355\n",
      "Configuration saved in train_with_reg/checkpoint-2355/config.json\n",
      "Model weights saved in train_with_reg/checkpoint-2355/pytorch_model.bin\n",
      "tokenizer config file saved in train_with_reg/checkpoint-2355/tokenizer_config.json\n",
      "Special tokens file saved in train_with_reg/checkpoint-2355/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 807\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to train_with_reg/checkpoint-2826\n",
      "Configuration saved in train_with_reg/checkpoint-2826/config.json\n",
      "Model weights saved in train_with_reg/checkpoint-2826/pytorch_model.bin\n",
      "tokenizer config file saved in train_with_reg/checkpoint-2826/tokenizer_config.json\n",
      "Special tokens file saved in train_with_reg/checkpoint-2826/special_tokens_map.json\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Prediction *****\n",
      "  Num examples = 807\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='114' max='101' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [101/101 00:05]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Prediction *****\n",
      "  Num examples = 52\n",
      "  Batch size = 8\n",
      "***** Running Prediction *****\n",
      "  Num examples = 48\n",
      "  Batch size = 8\n",
      "/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:309: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  FutureWarning,\n",
      "***** Running training *****\n",
      "  Num examples = 3765\n",
      "  Num Epochs = 6\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 2826\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2826' max='2826' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2826/2826 07:11, Epoch 6/6]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.066600</td>\n",
       "      <td>0.553027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.057100</td>\n",
       "      <td>0.529381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.057300</td>\n",
       "      <td>0.538101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.053800</td>\n",
       "      <td>0.538132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.052100</td>\n",
       "      <td>0.540431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.046300</td>\n",
       "      <td>0.539368</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 808\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to train_with_reg/checkpoint-471\n",
      "Configuration saved in train_with_reg/checkpoint-471/config.json\n",
      "Model weights saved in train_with_reg/checkpoint-471/pytorch_model.bin\n",
      "tokenizer config file saved in train_with_reg/checkpoint-471/tokenizer_config.json\n",
      "Special tokens file saved in train_with_reg/checkpoint-471/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 808\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to train_with_reg/checkpoint-942\n",
      "Configuration saved in train_with_reg/checkpoint-942/config.json\n",
      "Model weights saved in train_with_reg/checkpoint-942/pytorch_model.bin\n",
      "tokenizer config file saved in train_with_reg/checkpoint-942/tokenizer_config.json\n",
      "Special tokens file saved in train_with_reg/checkpoint-942/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 808\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to train_with_reg/checkpoint-1413\n",
      "Configuration saved in train_with_reg/checkpoint-1413/config.json\n",
      "Model weights saved in train_with_reg/checkpoint-1413/pytorch_model.bin\n",
      "tokenizer config file saved in train_with_reg/checkpoint-1413/tokenizer_config.json\n",
      "Special tokens file saved in train_with_reg/checkpoint-1413/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 808\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to train_with_reg/checkpoint-1884\n",
      "Configuration saved in train_with_reg/checkpoint-1884/config.json\n",
      "Model weights saved in train_with_reg/checkpoint-1884/pytorch_model.bin\n",
      "tokenizer config file saved in train_with_reg/checkpoint-1884/tokenizer_config.json\n",
      "Special tokens file saved in train_with_reg/checkpoint-1884/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 808\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to train_with_reg/checkpoint-2355\n",
      "Configuration saved in train_with_reg/checkpoint-2355/config.json\n",
      "Model weights saved in train_with_reg/checkpoint-2355/pytorch_model.bin\n",
      "tokenizer config file saved in train_with_reg/checkpoint-2355/tokenizer_config.json\n",
      "Special tokens file saved in train_with_reg/checkpoint-2355/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 808\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to train_with_reg/checkpoint-2826\n",
      "Configuration saved in train_with_reg/checkpoint-2826/config.json\n",
      "Model weights saved in train_with_reg/checkpoint-2826/pytorch_model.bin\n",
      "tokenizer config file saved in train_with_reg/checkpoint-2826/tokenizer_config.json\n",
      "Special tokens file saved in train_with_reg/checkpoint-2826/special_tokens_map.json\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Prediction *****\n",
      "  Num examples = 808\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='117' max='101' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [101/101 00:05]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Prediction *****\n",
      "  Num examples = 64\n",
      "  Batch size = 8\n",
      "***** Running Prediction *****\n",
      "  Num examples = 61\n",
      "  Batch size = 8\n",
      "/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:309: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  FutureWarning,\n",
      "***** Running training *****\n",
      "  Num examples = 3770\n",
      "  Num Epochs = 6\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 2832\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2832' max='2832' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2832/2832 07:11, Epoch 6/6]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.062300</td>\n",
       "      <td>0.571692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.061900</td>\n",
       "      <td>0.551847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.055800</td>\n",
       "      <td>0.543761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.053500</td>\n",
       "      <td>0.539321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.052300</td>\n",
       "      <td>0.543366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.046400</td>\n",
       "      <td>0.544558</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 808\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to train_with_reg/checkpoint-472\n",
      "Configuration saved in train_with_reg/checkpoint-472/config.json\n",
      "Model weights saved in train_with_reg/checkpoint-472/pytorch_model.bin\n",
      "tokenizer config file saved in train_with_reg/checkpoint-472/tokenizer_config.json\n",
      "Special tokens file saved in train_with_reg/checkpoint-472/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 808\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to train_with_reg/checkpoint-944\n",
      "Configuration saved in train_with_reg/checkpoint-944/config.json\n",
      "Model weights saved in train_with_reg/checkpoint-944/pytorch_model.bin\n",
      "tokenizer config file saved in train_with_reg/checkpoint-944/tokenizer_config.json\n",
      "Special tokens file saved in train_with_reg/checkpoint-944/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 808\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to train_with_reg/checkpoint-1416\n",
      "Configuration saved in train_with_reg/checkpoint-1416/config.json\n",
      "Model weights saved in train_with_reg/checkpoint-1416/pytorch_model.bin\n",
      "tokenizer config file saved in train_with_reg/checkpoint-1416/tokenizer_config.json\n",
      "Special tokens file saved in train_with_reg/checkpoint-1416/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 808\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to train_with_reg/checkpoint-1888\n",
      "Configuration saved in train_with_reg/checkpoint-1888/config.json\n",
      "Model weights saved in train_with_reg/checkpoint-1888/pytorch_model.bin\n",
      "tokenizer config file saved in train_with_reg/checkpoint-1888/tokenizer_config.json\n",
      "Special tokens file saved in train_with_reg/checkpoint-1888/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 808\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to train_with_reg/checkpoint-2360\n",
      "Configuration saved in train_with_reg/checkpoint-2360/config.json\n",
      "Model weights saved in train_with_reg/checkpoint-2360/pytorch_model.bin\n",
      "tokenizer config file saved in train_with_reg/checkpoint-2360/tokenizer_config.json\n",
      "Special tokens file saved in train_with_reg/checkpoint-2360/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 808\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to train_with_reg/checkpoint-2832\n",
      "Configuration saved in train_with_reg/checkpoint-2832/config.json\n",
      "Model weights saved in train_with_reg/checkpoint-2832/pytorch_model.bin\n",
      "tokenizer config file saved in train_with_reg/checkpoint-2832/tokenizer_config.json\n",
      "Special tokens file saved in train_with_reg/checkpoint-2832/special_tokens_map.json\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Prediction *****\n",
      "  Num examples = 808\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='119' max='101' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [101/101 00:05]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Prediction *****\n",
      "  Num examples = 68\n",
      "  Batch size = 8\n",
      "***** Running Prediction *****\n",
      "  Num examples = 65\n",
      "  Batch size = 8\n",
      "/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:309: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  FutureWarning,\n",
      "***** Running training *****\n",
      "  Num examples = 3766\n",
      "  Num Epochs = 6\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 2826\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2826' max='2826' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2826/2826 07:12, Epoch 6/6]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.055700</td>\n",
       "      <td>0.554165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.052200</td>\n",
       "      <td>0.539601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.049900</td>\n",
       "      <td>0.567640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.045200</td>\n",
       "      <td>0.546591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.043900</td>\n",
       "      <td>0.548949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.039100</td>\n",
       "      <td>0.547183</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 807\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to train_with_reg/checkpoint-471\n",
      "Configuration saved in train_with_reg/checkpoint-471/config.json\n",
      "Model weights saved in train_with_reg/checkpoint-471/pytorch_model.bin\n",
      "tokenizer config file saved in train_with_reg/checkpoint-471/tokenizer_config.json\n",
      "Special tokens file saved in train_with_reg/checkpoint-471/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 807\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to train_with_reg/checkpoint-942\n",
      "Configuration saved in train_with_reg/checkpoint-942/config.json\n",
      "Model weights saved in train_with_reg/checkpoint-942/pytorch_model.bin\n",
      "tokenizer config file saved in train_with_reg/checkpoint-942/tokenizer_config.json\n",
      "Special tokens file saved in train_with_reg/checkpoint-942/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 807\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to train_with_reg/checkpoint-1413\n",
      "Configuration saved in train_with_reg/checkpoint-1413/config.json\n",
      "Model weights saved in train_with_reg/checkpoint-1413/pytorch_model.bin\n",
      "tokenizer config file saved in train_with_reg/checkpoint-1413/tokenizer_config.json\n",
      "Special tokens file saved in train_with_reg/checkpoint-1413/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 807\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to train_with_reg/checkpoint-1884\n",
      "Configuration saved in train_with_reg/checkpoint-1884/config.json\n",
      "Model weights saved in train_with_reg/checkpoint-1884/pytorch_model.bin\n",
      "tokenizer config file saved in train_with_reg/checkpoint-1884/tokenizer_config.json\n",
      "Special tokens file saved in train_with_reg/checkpoint-1884/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 807\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to train_with_reg/checkpoint-2355\n",
      "Configuration saved in train_with_reg/checkpoint-2355/config.json\n",
      "Model weights saved in train_with_reg/checkpoint-2355/pytorch_model.bin\n",
      "tokenizer config file saved in train_with_reg/checkpoint-2355/tokenizer_config.json\n",
      "Special tokens file saved in train_with_reg/checkpoint-2355/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 807\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to train_with_reg/checkpoint-2826\n",
      "Configuration saved in train_with_reg/checkpoint-2826/config.json\n",
      "Model weights saved in train_with_reg/checkpoint-2826/pytorch_model.bin\n",
      "tokenizer config file saved in train_with_reg/checkpoint-2826/tokenizer_config.json\n",
      "Special tokens file saved in train_with_reg/checkpoint-2826/special_tokens_map.json\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Prediction *****\n",
      "  Num examples = 807\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='118' max='101' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [101/101 00:05]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Prediction *****\n",
      "  Num examples = 65\n",
      "  Batch size = 8\n",
      "***** Running Prediction *****\n",
      "  Num examples = 61\n",
      "  Batch size = 8\n"
     ]
    }
   ],
   "source": [
    "a_lst = []\n",
    "b_lst = []\n",
    "c_lst = []\n",
    "\n",
    "for g in tqdm(group_lst):\n",
    "\n",
    "    trainer2 = Trainer(\n",
    "    model,\n",
    "    args,\n",
    "    train_dataset=train_dict[g],\n",
    "    eval_dataset=dev_a_dict[g],\n",
    "    tokenizer=tokenizer)\n",
    "\n",
    "    trainer2.train()\n",
    "\n",
    "    # (a) Evaluation\n",
    "    pred_a = trainer2.predict(dev_a_dict[g])\n",
    "    a_lst.append(pearsonr(pred_a.label_ids, pred_a.predictions.flatten())[0])\n",
    "\n",
    "    # (b) Evaluation\n",
    "    pred_b = trainer2.predict(dev_b_dict[g])\n",
    "    b_lst.append(pearsonr(pred_b.label_ids, pred_b.predictions.flatten())[0])\n",
    "\n",
    "    # (c) Evaluation\n",
    "    pred_c = trainer2.predict(dev_c_dict[g])\n",
    "    c_lst.append(pearsonr(pred_c.label_ids, pred_c.predictions.flatten())[0])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 557
    },
    "id": "W1FSIKJdTuKr",
    "outputId": "5ea13daa-cdae-4efa-9ae3-b86ac9cabd60"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 2160x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize = (30,10))\n",
    "plt.xticks(fontsize=18)\n",
    "plt.yticks(fontsize=18)\n",
    "x = list(range(len(group_lst[:12])))\n",
    "total_width, n = 0.75, 3\n",
    "width = total_width / n\n",
    "plt.bar(x, a_lst[:12], width=width, label='a')\n",
    "for i in range(len(x)):\n",
    "    x[i] = x[i] + width\n",
    "plt.bar(x, b_lst[:12], width=width, label='b', tick_label=group_lst[:12])\n",
    "for i in range(len(x)):\n",
    "    x[i] = x[i] + width\n",
    "plt.bar(x, c_lst[:12], width=width, label='c')\n",
    "for i in range(len(x)):\n",
    "    x[i] = x[i] + width\n",
    "plt.legend(loc=1, prop={'size': 20})\n",
    "plt.xlabel('Group', fontdict={'size': 20})\n",
    "plt.ylabel('Correlation', fontdict={'size': 20})\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 557
    },
    "id": "pcFbrzsTUdj_",
    "outputId": "c727b7c2-91ba-465d-9a7b-a0f0db43b6c6"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 2160x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize = (30,10))\n",
    "plt.xticks(fontsize=18)\n",
    "plt.yticks(fontsize=18)\n",
    "x = list(range(len(group_lst[12:])))\n",
    "total_width, n = 0.75, 3\n",
    "width = total_width / n\n",
    "plt.bar(x, a_lst[12:], width=width, label='a')\n",
    "for i in range(len(x)):\n",
    "    x[i] = x[i] + width\n",
    "plt.bar(x, b_lst[12:], width=width, label='b', tick_label=group_lst[12:])\n",
    "for i in range(len(x)):\n",
    "    x[i] = x[i] + width\n",
    "plt.bar(x, c_lst[12:], width=width, label='c')\n",
    "for i in range(len(x)):\n",
    "    x[i] = x[i] + width\n",
    "plt.legend(loc=1, prop={'size': 20})\n",
    "plt.xlabel('Group', fontdict={'size': 20})\n",
    "plt.ylabel('Correlation', fontdict={'size': 20})\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "id": "0W2Hq5JJDncS"
   },
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# save the correlation data\n",
    "filename = \"Correlation_result.json\"\n",
    "js_out = {}\n",
    "js_out['a'] = a_lst\n",
    "js_out['b'] = b_lst\n",
    "js_out['c'] = c_lst\n",
    "\n",
    "with open(filename, \"w\") as f:\n",
    "  json.dump(js_out, f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zXM5U0vTGdP2"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Bert_reg.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "1beab673debf4b11af3cd537351e4200": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "24731db8569c4271bb8005ad21510a20": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_8de35ac403ad45369837f1680a83080a",
      "placeholder": "​",
      "style": "IPY_MODEL_9c33f9c1e1774bb5a43e72ef32b7adff",
      "value": " 24/24 [2:54:57&lt;00:00, 437.09s/it]"
     }
    },
    "277d4b2c1621478b9202f6cad2944e66": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "2c72af6399954523b3e9441e420c7848": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "3df8faa69fdf4903a3a39fb11680f9c1": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "51940ef27e364ae0a690426addf49cc6": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_c7d02bec4b9b4bea921232ba93247b50",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_c57cc4641cfb4af28283f539f62ae57a",
      "value": 1
     }
    },
    "5a82eb9826d7462d9f19a9cf4aafc708": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_2c72af6399954523b3e9441e420c7848",
      "placeholder": "​",
      "style": "IPY_MODEL_c190e36ed94f473b8db940d6176bf624",
      "value": "100%"
     }
    },
    "610a54182baf4fe886c55b27d4d59c03": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "6849ae29b37442eeaa49e539cc5690ab": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "738120ddbf9d4d95abb50f725475be79": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_5a82eb9826d7462d9f19a9cf4aafc708",
       "IPY_MODEL_d3d6c2d41c344c2b9f529d74e11fccc3",
       "IPY_MODEL_24731db8569c4271bb8005ad21510a20"
      ],
      "layout": "IPY_MODEL_3df8faa69fdf4903a3a39fb11680f9c1"
     }
    },
    "744aa07bf14a4dfe986992147dd7dba9": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "88a870f65d8e4811adb92dc17397e45b": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "8de35ac403ad45369837f1680a83080a": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "9c33f9c1e1774bb5a43e72ef32b7adff": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "b05a28b4720345c3b7c0cad404134418": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_277d4b2c1621478b9202f6cad2944e66",
      "placeholder": "​",
      "style": "IPY_MODEL_f72be50f00c244f28b1f85a0e8b2d1d7",
      "value": "100%"
     }
    },
    "b4f0e06f9d554ad2aabb3f39f1b3c390": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_744aa07bf14a4dfe986992147dd7dba9",
      "placeholder": "​",
      "style": "IPY_MODEL_6849ae29b37442eeaa49e539cc5690ab",
      "value": " 1/1 [00:00&lt;00:00,  2.34ba/s]"
     }
    },
    "c190e36ed94f473b8db940d6176bf624": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "c57cc4641cfb4af28283f539f62ae57a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "c7d02bec4b9b4bea921232ba93247b50": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c9ff2787542f4d6c91699c0e1afcc897": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_b05a28b4720345c3b7c0cad404134418",
       "IPY_MODEL_51940ef27e364ae0a690426addf49cc6",
       "IPY_MODEL_b4f0e06f9d554ad2aabb3f39f1b3c390"
      ],
      "layout": "IPY_MODEL_88a870f65d8e4811adb92dc17397e45b"
     }
    },
    "d3d6c2d41c344c2b9f529d74e11fccc3": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_610a54182baf4fe886c55b27d4d59c03",
      "max": 24,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_1beab673debf4b11af3cd537351e4200",
      "value": 24
     }
    },
    "f72be50f00c244f28b1f85a0e8b2d1d7": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
