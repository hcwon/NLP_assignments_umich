{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SI630 Homework 2: Word2vec Vector Analysis\n",
    "\n",
    "*Important Note:* Start this notebook only after you've gotten your word2vec model up and running!\n",
    "\n",
    "Many NLP packages support working with word embeddings. In this notebook you can work through the various problems assigned in Task 3. We've provided the basic functionality for loading word vectors using [Gensim](https://radimrehurek.com/gensim/models/keyedvectors.html), a good library for learning and using word vectors, and for working with the vectors. \n",
    "\n",
    "One of the fun parts of word vectors is getting a sense of what they learned. Feel free to explore the vectors here! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import KeyedVectors\n",
    "from gensim.test.utils import datapath\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_vectors = KeyedVectors.load_word2vec_format('batch64_epoch2.kv', binary=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.19241408,  0.2576456 ,  0.2935388 ,  0.11680046,  0.31052843,\n",
       "        0.32328594,  0.05061395,  0.44246665, -0.33109954,  0.2731386 ,\n",
       "        0.40557373, -0.00654686, -0.19519377, -0.10499651,  0.42710277,\n",
       "        0.3476099 ,  0.27773622, -0.3382859 , -0.3124103 ,  0.07280707,\n",
       "       -0.37873477, -0.4160243 ,  0.26094747,  0.13683128, -0.35059485,\n",
       "        0.13617794, -0.23732208, -0.22580446,  0.0408926 ,  0.28133357,\n",
       "        0.3918162 , -0.2962489 , -0.089159  , -0.18824862,  0.0928667 ,\n",
       "        0.46785083,  0.27270508, -0.11240458,  0.3881742 , -0.09735969,\n",
       "       -0.2333183 ,  0.13097619, -0.36377218,  0.12355022, -0.41767976,\n",
       "       -0.26968378,  0.13717325, -0.07116733, -0.12750266, -0.22033277],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_vectors['father']  # \"the\" is stopword which is removed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('articles', 0.9663563370704651),\n",
       " ('poems', 0.9478422403335571),\n",
       " ('novels', 0.9460662007331848),\n",
       " ('stories', 0.9414302706718445),\n",
       " ('contributed', 0.9412834048271179),\n",
       " ('paintings', 0.9386244416236877),\n",
       " ('works', 0.9363186955451965),\n",
       " ('include', 0.9328792691230774),\n",
       " ('collection', 0.9259740114212036),\n",
       " ('many', 0.9233297109603882)]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_vectors.similar_by_word(\"books\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('mother', 0.9696972370147705),\n",
       " ('grandfather', 0.9631543159484863),\n",
       " ('heir', 0.9610350131988525),\n",
       " ('paternal', 0.9595015048980713),\n",
       " ('maternal', 0.9547305107116699),\n",
       " ('elder', 0.9497459530830383),\n",
       " ('grandparents', 0.9496219158172607),\n",
       " ('inherited', 0.9467555284500122),\n",
       " ('dowager', 0.9460021257400513),\n",
       " ('grandmother', 0.9399321675300598)]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_vectors.similar_by_word(\"father\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('june', 0.9970817565917969),\n",
       " ('february', 0.9964244365692139),\n",
       " ('october', 0.9964032769203186),\n",
       " ('july', 0.9963155388832092),\n",
       " ('april', 0.9958195686340332),\n",
       " ('march', 0.9956510663032532),\n",
       " ('november', 0.9955711960792542),\n",
       " ('september', 0.9953199028968811),\n",
       " ('january', 0.9950190186500549),\n",
       " ('august', 0.9944725036621094)]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_vectors.similar_by_word(\"december\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('prosody', 0.9881281852722168),\n",
       " ('shifting', 0.987313985824585),\n",
       " ('reacting', 0.9868288040161133),\n",
       " ('detector', 0.986199676990509),\n",
       " ('spotlight', 0.9858798384666443),\n",
       " ('revisionist', 0.9844568967819214),\n",
       " ('notoriety', 0.9843422174453735),\n",
       " ('interconnected', 0.983756422996521),\n",
       " ('obie', 0.9835957288742065),\n",
       " ('trending', 0.983402669429779)]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_vectors.similar_by_word(\"vector\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('taipei', 0.9849403500556946),\n",
       " ('kenya', 0.9768831729888916),\n",
       " ('southwest', 0.9754226207733154),\n",
       " ('philippines', 0.9733985662460327),\n",
       " ('armenia', 0.9723545908927917),\n",
       " ('nigeria', 0.967566728591919),\n",
       " ('yerevan', 0.9674270749092102),\n",
       " ('akwa', 0.9668207168579102),\n",
       " ('ghana', 0.9664041996002197),\n",
       " ('otago', 0.9648773074150085)]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_vectors.similar_by_word(\"shanghai\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('college', 0.937831461429596),\n",
       " ('graduated', 0.9327039122581482),\n",
       " ('degree', 0.9204564094543457),\n",
       " ('graduating', 0.9166544079780579),\n",
       " ('bachelor', 0.9162642955780029),\n",
       " ('school', 0.8914241194725037),\n",
       " ('ba', 0.8892958164215088),\n",
       " ('obtained', 0.8833814859390259),\n",
       " ('ph', 0.8819765448570251),\n",
       " ('completed', 0.8810583353042603)]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_vectors.similar_by_word(\"university\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('theatrical', 0.9825085401535034),\n",
       " ('influences', 0.9811133742332458),\n",
       " ('hindi', 0.9802998304367065),\n",
       " ('actors', 0.9774397015571594),\n",
       " ('cinema', 0.9762035608291626),\n",
       " ('malayalam', 0.974105954170227),\n",
       " ('folk', 0.9738557934761047),\n",
       " ('personality', 0.9732572436332703),\n",
       " ('composing', 0.9709309935569763),\n",
       " ('romance', 0.9703514575958252)]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_vectors.similar_by_word(\"model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('hopes', 0.9627960920333862),\n",
       " ('fitness', 0.9622615575790405),\n",
       " ('quit', 0.9568812251091003),\n",
       " ('turning', 0.9555206298828125),\n",
       " ('combine', 0.9532834887504578),\n",
       " ('consistent', 0.9516782760620117),\n",
       " ('struggling', 0.9507704377174377),\n",
       " ('switching', 0.9496033787727356),\n",
       " ('switched', 0.9464257955551147),\n",
       " ('parent', 0.9443178772926331)]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_vectors.similar_by_word(\"begin\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('computer', 0.9675750732421875),\n",
       " ('physics', 0.9639965295791626),\n",
       " ('technology', 0.9628846049308777),\n",
       " ('doctoral', 0.9600778222084045),\n",
       " ('engineering', 0.960049033164978),\n",
       " ('philosophy', 0.9584078788757324),\n",
       " ('fine', 0.9578328728675842),\n",
       " ('research', 0.9577223062515259),\n",
       " ('arts', 0.9556991457939148),\n",
       " ('diploma', 0.9553272128105164)]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_vectors.similar_by_word(\"science\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('photographic', 0.9966528415679932),\n",
       " ('designing', 0.9951133131980896),\n",
       " ('pioneering', 0.9948294758796692),\n",
       " ('aesthetic', 0.9937834143638611),\n",
       " ('topic', 0.9933844208717346),\n",
       " ('craft', 0.9933729767799377),\n",
       " ('explored', 0.9932363629341125),\n",
       " ('perspective', 0.9931826591491699),\n",
       " ('approaches', 0.9926080703735352),\n",
       " ('concepts', 0.9925568103790283)]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_vectors.similar_by_word(\"creativity\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### I find that the model perform well in most cases above. Especially for some common word with unique meaning like december. Even for some less common word like shanghai, but it has very specific meaning, the model also can identify it as a location. However, for some verb, I find the performance is worse than nouns. Use \"begin\" as example, the returned result is very confusing. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_analogy(a, b, c):\n",
    "    return word_vectors.most_similar(positive=[b, c], negative=[a])[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'queen'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_analogy('man', 'woman', 'king')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'japanese'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_analogy('korea', 'japan', 'korean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'london'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_analogy('france', 'england', 'paris')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'twice'"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_analogy('one', 'two', 'first')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'papers'"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_analogy('book', 'article', 'books')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### I find when the word is some noun with very specific meaning and stable use like natianlity, language, capital, the model performs well. For example, \"Japanese\" - \"japan\" = \"korean\" - \"korea\" and \"paris\" - \"france\" = \"london\" - \"england\". However, the model also doesnot perform well in some aspects. 'one', 'two', 'first', the model does detect it should return some words related two, but it returned twice instead of second. Also, when it comes to 'book', 'article', 'books', the model knows it should return plural form but it return papers instead of articles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
